{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucile/causal_info_gain/pjake/lib/python3.9/site-packages/torch/__init__.py:696: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:453.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "torch.set_default_tensor_type(torch.FloatTensor) \n",
    "import copy\n",
    "\n",
    "from rct_data_generator import *\n",
    "from outcome_models import *\n",
    "from plotting_functions import *\n",
    "from mcmc_bayes_update import *\n",
    "from eig_comp_utils import *\n",
    "from research_exp_utils import *\n",
    "import uci_dataset as dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Simulating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "\n",
    "n_rct_before_split = 10**6\n",
    "n_host = 2000\n",
    "sigma_prior = 1\n",
    "sigma_rand_error = 1\n",
    "\n",
    "power_x, power_x_t = 1, 1\n",
    "std_true_y = 1 # Standard deviation for the true Y\n",
    "\n",
    "\n",
    "# X0 = np.random.beta(12, 3, size= n_rct_before_split)\n",
    "# X1 = np.random.normal(loc=4, scale=1, size=n_rct_before_split)\n",
    "# X2 = np.random.beta(1, 7, size=n_rct_before_split)\n",
    "# x_distributions= {0: X0, 1: X1, 2:X2}\n",
    "# d = 1 + len(x_distributions)*(power_x) + 1 + len(x_distributions)*(power_x_t)\n",
    "\n",
    "\n",
    "#p_assigned_to_host = lambda X_0, X_1, T, eps: sigmoid(1 + 2*X_0 - X_1 + 3*T + eps)\n",
    "# p_assigned_to_host = lambda X, T, eps: sigmoid(1 + 2*X['X_0'] - X['X_1'] + 3*T + eps)\n",
    "# p_assigned_to_cand2 = lambda X_0, X_1, T, eps: sigmoid(1 + 2*X_0 - X_1 + 3*T + eps) #can't take X_2, harcoded still"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight.whole</th>\n",
       "      <th>Weight.shucked</th>\n",
       "      <th>Weight.viscera</th>\n",
       "      <th>Weight.shell</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.8705</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.2190</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.235</td>\n",
       "      <td>1.0640</td>\n",
       "      <td>0.4130</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.175</td>\n",
       "      <td>1.1650</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.2205</td>\n",
       "      <td>0.3055</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.175</td>\n",
       "      <td>1.3345</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>0.2665</td>\n",
       "      <td>0.3550</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.180</td>\n",
       "      <td>1.4545</td>\n",
       "      <td>0.6315</td>\n",
       "      <td>0.3105</td>\n",
       "      <td>0.3725</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex  Length  Diameter  Height  Weight.whole  Weight.shucked  \\\n",
       "0  1.0   0.520      0.41   0.170        0.8705          0.3735   \n",
       "1  0.0   0.635      0.48   0.235        1.0640          0.4130   \n",
       "2  1.0   0.580      0.46   0.175        1.1650          0.6500   \n",
       "3  1.0   0.645      0.52   0.175        1.3345          0.6670   \n",
       "4  0.0   0.685      0.51   0.180        1.4545          0.6315   \n",
       "\n",
       "   Weight.viscera  Weight.shell  Rings  \n",
       "0          0.2190        0.2500     14  \n",
       "1          0.2280        0.3600     16  \n",
       "2          0.2205        0.3055      9  \n",
       "3          0.2665        0.3550     10  \n",
       "4          0.3105        0.3725      9  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone = dataset.load_abalone()\n",
    "abalone['Sex'] = abalone['Sex'].map({'M': 0, 'F': 1})\n",
    "abalone.dropna(inplace=True)\n",
    "resampled_abalone = [abalone.sample(frac=1, replace=True) for _ in range(5*(10**3))]\n",
    "# Concatenate resampled DataFrames\n",
    "abalone = pd.concat(resampled_abalone, ignore_index=True)\n",
    "\n",
    "causal_param_first_index = power_x * np.shape(abalone)[1] + 1\n",
    "\n",
    "abalone.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_x_dim = np.shape(abalone)[1]\n",
    "initial_n_entire_data = np.shape(abalone)[0]\n",
    "x_distributions={}\n",
    "\n",
    "for column in abalone.columns:\n",
    "    x_distributions[column] = abalone[column].values\n",
    "\n",
    "# simulate T\n",
    "T_rct = np.random.randint(2, size=initial_n_entire_data)\n",
    "p_assigned_to_host = lambda X, T, eps: 0.5 #sigmoid(1 + 2*X['Sex'] - X['Weight.viscera'] + 12*np.sqrt(X['Diameter']) + np.log(X['Weight.shell']) + 3*T + eps)\n",
    "p_assigned_to_cand2 = lambda X, T, eps: 0.5 #sigmoid(1 + 2*X['Sex'] - X['Weight.viscera'] + 12*np.sqrt(X['Diameter']) + np.log(X['Weight.shell']) + 3*T + eps)\n",
    "\n",
    "d = 1 + initial_x_dim*(power_x) + 1 + len(x_distributions)*(power_x_t)\n",
    "outcome_function = lambda X, T, eps: 1 + 1 * X['Sex'] - 1 * X['Weight.viscera'] + np.log(X['Weight.whole']) - X['Height'] + 4 * T + 2* X['Weight.shucked']*T + 24* X['Weight.shell']*T + 0* X['Weight.shucked']*T + eps \n",
    "# outcome_function = lambda X, T, eps: 1 + 1 * X[:,0] - 1 * X[:,1] + 1 * X[:,2] + 4 * T + 2* X[:,0]*T + 24* X[:,1]*T + 0* X[:,2]*T + eps "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior parameters for Bayesian update on host\n",
    "prior_mean = torch.zeros(d)\n",
    "beta_0, sigma_0_sq, inv_cov_0 = prior_mean, sigma_rand_error,torch.eye(d)\n",
    "prior_hyperparameters = {'beta_0': beta_0, 'sigma_0_sq': sigma_0_sq,\"inv_cov_0\":inv_cov_0}\n",
    "\n",
    "# Hyperparameters for Bayesian update on host\n",
    "warmup_steps = 50\n",
    "max_tree_depth = 5\n",
    "\n",
    "# Number of samples used to estimate outer expectation\n",
    "n_samples_for_expectation = 50\n",
    "m_samples_for_expectation = 1000\n",
    "\n",
    "\n",
    "# Incorporating sqrt constraint into MCMC samples\n",
    "n_mc = (n_samples_for_expectation * (m_samples_for_expectation+1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_both_candidates_list = [200, 500, 1000]\n",
    "proportion = 1 #n_cand2 = prorportion * n_both_candidates_list\n",
    "std_true_y = 1\n",
    "\n",
    "\n",
    "data_parameters = {'n_both_candidates_list': n_both_candidates_list, 'proportion':proportion, 'n_rct_before_split':n_rct_before_split, \\\n",
    "                   'x_distributions':x_distributions, 'p_assigned_to_cand2':p_assigned_to_cand2, 'n_host':n_host, 'power_x':power_x, \\\n",
    "                    'power_x_t':power_x_t, 'outcome_function':outcome_function, 'std_true_y':std_true_y, 'causal_param_first_index':causal_param_first_index}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. EIG closed form for varying sample sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_seeds=10\n",
    "plot_additional = True\n",
    "\n",
    "text_l1 ='p_assigned_to_host = p_assigned_to_cand2, approx 0.75 of treated in host, '\n",
    "text_l2 = 'n_host = '+str(n_host)+', sigma_prior = sigma_rand_error = '+str(sigma_rand_error)\n",
    "text_l3 = 'outcome_function = 1 + 1 * X[:,0] - 1 * X[:,1] + 1 * X[:,2] + 4 * T + 2* X[:,0]*T + 24* X[:,1]*T + 0* X[:,2]*T + eps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "eig_closed_form_varying_sample_size() missing 2 required positional arguments: 'prior_hyperparameters' and 'n_mc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m EIG_obs_closed_form, EIG_caus_closed_form \u001b[38;5;241m=\u001b[39m \u001b[43meig_closed_form_varying_sample_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabalone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma_rand_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior_hyperparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_mc\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: eig_closed_form_varying_sample_size() missing 2 required positional arguments: 'prior_hyperparameters' and 'n_mc'"
     ]
    }
   ],
   "source": [
    "EIG_obs_closed_form, EIG_caus_closed_form = eig_closed_form_varying_sample_size(abalone, T, data_parameters, sigma_rand_error, prior_hyperparameters, n_mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not plot_additional:\n",
    "    dict_additional_plots_obs = dict_additional_plots_caus = {'Exact complementary':0, 'Exact twin': 0, 'Exact twin treated': 0, 'Exact twin untreated': 0}\n",
    "\n",
    "else:\n",
    "    dict_additional_plots_obs, dict_additional_plots_caus = eig_closed_form_exact_datasets(data_parameters, sigma_rand_error, prior_hyperparameters, n_mc)\n",
    "\n",
    "EIG_obs_closed_form_across_seeds, EIG_caus_closed_form_across_seeds = [], []\n",
    "\n",
    "for i in range (n_seeds):\n",
    "    EIG_obs_closed_form, EIG_caus_closed_form = eig_closed_form_varying_sample_size(X_rct, T_rct, data_parameters, sigma_rand_error, prior_hyperparameters, n_mc, synthetic=False)\n",
    "    if len(EIG_obs_closed_form_across_seeds)==0:\n",
    "        EIG_obs_closed_form_across_seeds= EIG_obs_closed_form\n",
    "        EIG_caus_closed_form_across_seeds = EIG_caus_closed_form\n",
    "    else:\n",
    "        EIG_obs_closed_form_across_seeds = np.vstack((EIG_obs_closed_form_across_seeds, EIG_obs_closed_form))\n",
    "        EIG_caus_closed_form_across_seeds = np.vstack((EIG_caus_closed_form_across_seeds, EIG_caus_closed_form))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_obs_closed_form = '/Users/lucile/causal_info_gain/plots/eig_obs_closed_form'\n",
    "# path_obs_closed_form = 0\n",
    "alpha = 0.3\n",
    "\n",
    "plot_array(dict_additional_plots_obs, n_both_candidates_list, EIG_obs_closed_form_across_seeds, axis_names= ['Sample size of candidate datasets', 'EIG predictive'], names=['complementary','twin'],\n",
    "           text= text_l1+ '\\n' + text_l2+ '\\n' + text_l3, title= 'EIG predictive', save=path_obs_closed_form, alpha = alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_caus_closed_form = '/Users/lucile/causal_info_gain/plots/eig_caus_closed_form'\n",
    "# path_caus_closed_form = 0\n",
    "alpha = 0.3\n",
    "\n",
    "plot_array(dict_additional_plots_caus, n_both_candidates_list, EIG_caus_closed_form_across_seeds, axis_names= ['Sample size of candidate datasets', 'EIG causal'], names=['complementary','twin'],\n",
    "           text= text_l1+ '\\n' + text_l2+ '\\n' + text_l3, title= 'EIG causal', save=path_caus_closed_form, alpha = alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. EIG from samples for varying sample sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_outer_expectation = 800\n",
    "n_samples_inner_expectation = 200\n",
    "n_causal_outer_exp = 800\n",
    "n_causal_inner_exp = 200\n",
    "\n",
    "sampling_parameters = {'n_samples_inner_expectation':n_samples_inner_expectation, 'n_samples_outer_expectation':n_samples_outer_expectation, \\\n",
    "                       'n_causal_inner_exp':n_causal_inner_exp, 'n_causal_outer_exp':n_causal_outer_exp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_seeds = 2\n",
    "EIG_obs_samples_across_seeds, EIG_caus_samples_across_seeds = [], []\n",
    "\n",
    "for i in range (n_seeds):\n",
    "    EIG_obs_samples, EIG_caus_samples = eig_from_samples_varying_sample_size(data_parameters, sigma_rand_error, prior_hyperparameters, sampling_parameters)\n",
    "    if len(EIG_obs_samples_across_seeds)==0:\n",
    "        EIG_obs_samples_across_seeds= EIG_obs_samples\n",
    "        EIG_caus_samples_across_seeds = EIG_caus_samples\n",
    "    else:\n",
    "        EIG_obs_samples_across_seeds = np.vstack((EIG_obs_samples_across_seeds, EIG_obs_samples))\n",
    "        EIG_caus_samples_across_seeds = np.vstack((EIG_caus_samples_across_seeds, EIG_caus_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_l1 ='p_assigned_to_host=p_assigned_to_cand2, approx 0.8 treated in host'\n",
    "text_l2 = 'n_samples_inner_expectation = '+str(n_samples_inner_expectation)+ 'n_samples_outer_expectation = '+str(n_samples_outer_expectation)+', n_host = '+str(n_host)+', sigma_prior = sigma_rand_error = '+str(sigma_rand_error)\n",
    "text_l4 = 'n_host = 200, sigma_prior = sigma_rand_error = 1, n_causal_inner_exp = '+str(n_causal_inner_exp) \n",
    "\n",
    "\n",
    "plot_additional = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_additional = True\n",
    "if not plot_additional:\n",
    "    dict_additional_plots_obs = dict_additional_plots_caus = {'Exact complementary':0, 'Exact twin': 0, 'Exact twin treated': 0, 'Exact twin untreated': 0}\n",
    "\n",
    "else:\n",
    "    dict_additional_plots_obs, dict_additional_plots_caus = eig_closed_form_exact_datasets(data_parameters, sigma_rand_error, prior_hyperparameters, n_mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_obs_samples = '/Users/lucile/causal_info_gain/plots/eig_obs_samples'\n",
    "path_obs_samples = 0\n",
    "alpha = 0.3\n",
    "\n",
    "plot_array(dict_additional_plots_obs, n_both_candidates_list, EIG_obs_samples_across_seeds, axis_names= ['Sample size of candidate datasets', 'EIG predictive'], names=['complementary','twin'],\n",
    "           text= text_l1+ '\\n' + text_l2+ '\\n' + text_l3+ '\\n' + text_l4, title= 'EIG predictive', save=path_obs_samples, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_caus_samples = '/Users/lucile/causal_info_gain/plots/eig_caus_samples'\n",
    "path_caus_samples = 0\n",
    "alpha = 0.3\n",
    "\n",
    "plot_array(dict_additional_plots_caus, n_both_candidates_list, EIG_caus_samples_across_seeds, axis_names= ['Sample size of candidate datasets', 'EIG causal'], names=['complementary','twin'],\n",
    "           text= text_l1+ '\\n' + text_l2+ '\\n' + text_l3+ '\\n' + text_l4, title= 'EIG causal', save=path_caus_samples, alpha=alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extreme examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_host_sample = 500 \n",
    "# sigma_error = 1 \n",
    "\n",
    "# X_host = (torch.randn((n_host_sample,d)) @ A ) \n",
    "# T_host = torch.bernoulli(torch.sigmoid(X_host@ T_allocation_host))\n",
    "# X_host_times_T = (T_host.unsqueeze(dim=0).T * X_host)\n",
    "# X_host = torch.concat([X_host,X_host_times_T],dim=1)\n",
    "\n",
    "# Y_host = X_host @ mu\n",
    "# Y_host = (1/Y_host.norm()) * Y_host + sigma_error * torch.randn_like(Y_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior_mean = torch.zeros(2 * d)\n",
    "# beta_0, sigma_0_sq,inv_cov_0 = prior_mean, sigma_error,torch.eye(2*d)\n",
    "# prior_hyperparameters = {'beta_0': beta_0, 'sigma_0_sq': sigma_0_sq,\"inv_cov_0\":inv_cov_0}\n",
    "# bayesian_regression = BayesianLinearRegression(prior_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayesian_regression.fit(X_host,Y_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pjake_kernel",
   "language": "python",
   "name": "pjake_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
