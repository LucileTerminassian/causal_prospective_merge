{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucile/causal_info_gain/pjake/lib/python3.9/site-packages/torch/__init__.py:696: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:453.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "torch.set_default_tensor_type(torch.FloatTensor) \n",
    "import copy\n",
    "import sys\n",
    "import os\n",
    "notebook_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(notebook_dir)\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(parent_dir)\n",
    "sys.path.append('/Users/lucile/causal_info_gain/causal_prospective_merge/data')\n",
    "\n",
    "from rct_data_generator import *\n",
    "from outcome_models import *\n",
    "from plotting_functions import *\n",
    "from mcmc_bayes_update import *\n",
    "from eig_comp_utils import *\n",
    "from research_exp_utils import *\n",
    "import uci_dataset as dataset\n",
    "\n",
    "#maybe econml or causalml. So far can't get them to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/lucile/causal_info_gain/causal_prospective_merge/'\n",
    "data, x, t, y = get_data('twins', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_data = dataset.load_abalone()\n",
    "initial_data['Sex'] = initial_data['Sex'].map({'M': 0, 'F': 1})\n",
    "initial_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_candidate_sites = 10\n",
    "min_sample_size_cand = 150\n",
    "max_sample_size_cand = 250\n",
    "host_sample_size = 200\n",
    "desired_initial_sample_size = 10**6\n",
    "initial_data = initial_data.sample(n=desired_initial_sample_size, replace=True, random_state=42)\n",
    "\n",
    "\n",
    "outcome_function = lambda X, T, eps: 1 + 1 * X['Sex'] - 1 * X['Weight.viscera'] + np.log(X['Weight.whole']) - \\\n",
    "    X['Height'] + 4 * T + 2* X['Weight.shucked']*T + 24* X['Weight.shell']*T + 0* X['Weight.shucked']*T + eps \n",
    "std_true_y = 1\n",
    "power_x = 1\n",
    "power_x_t = 1\n",
    "sigma_rand_error = 1\n",
    "\n",
    "exp_parameters = {'number_of_candidate_sites': number_of_candidate_sites, 'min_sample_size_cand': min_sample_size_cand, \\\n",
    "                'max_sample_size_cand': max_sample_size_cand, 'host_sample_size': host_sample_size, 'outcome_function': outcome_function, \\\n",
    "                'std_true_y': std_true_y, 'power_x': power_x, 'power_x_t': power_x_t}\n",
    "\n",
    "causal_param_first_index = causal_param_first_index = power_x * np.shape(initial_data)[1] + 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_random_sites_from(data, exp_parameters):\n",
    "    sites = {}\n",
    "    sample_size, number_covariates = np.shape(data)[0], np.shape(data)[1]\n",
    "    function_indices = {0: lambda X: np.log(X+1), 1: lambda X: X**3, 2: lambda X: X, 3: lambda X: X**2}\n",
    "    T = new_df = pd.DataFrame({'T': np.random.randint(2, size=sample_size)}, index=data.index) \n",
    "    XandT = pd.concat([data, T], axis= 1)\n",
    "    number_of_candidate_sites = exp_parameters['number_of_candidate_sites']\n",
    "    min_sample_size_cand = exp_parameters['min_sample_size_cand']\n",
    "    max_sample_size_cand = exp_parameters['max_sample_size_cand']\n",
    "    outcome_function = exp_parameters['outcome_function']\n",
    "    std_true_y = exp_parameters['std_true_y']\n",
    "    power_x = exp_parameters['power_x']\n",
    "    power_x_t = exp_parameters['power_x_t']\n",
    "    number_features = number_covariates + 1\n",
    "    created_sites = 0\n",
    "    \n",
    "    while created_sites < number_of_candidate_sites:\n",
    "        \n",
    "        selected_features_for_subsampling = np.random.randint(2, size = number_features) \n",
    "        # binary bool vector representing selection for being an input of the sampling function\n",
    "        random_coefs = [np.random.uniform(-10, 10) for _ in range(number_features)] \n",
    "        random_fct_idx = [np.random.randint(0, 4) for _ in range(number_features)] \n",
    "        \n",
    "        def p_assigned_to_site(X, T, eps):\n",
    "            result = 0\n",
    "            for j in range(number_features-1):\n",
    "                result += selected_features_for_subsampling[j] * random_coefs[j] * function_indices[random_fct_idx[j]](X[j])\n",
    "            result += selected_features_for_subsampling[-1] * random_coefs[-1] *  function_indices[random_fct_idx[-1]](T)\n",
    "            return sigmoid(result + eps)\n",
    "        \n",
    "        sample_size = np.random.randint(min_sample_size_cand, max_sample_size_cand + 1)  # Add 1 to include max_sample_size_cand\n",
    "        design_data_cand = subsample_one_dataset(XandT, p_assigned_to_site, sample_size, power_x, power_x_t, outcome_function, std_true_y)\n",
    "        if not design_data_cand.empty:\n",
    "            sites[created_sites] = design_data_cand\n",
    "            created_sites += 1\n",
    "\n",
    "    return sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sex  Length  Diameter  Height  Weight.whole  Weight.shucked  \\\n",
      "1170  1.0   0.625     0.485   0.175        1.3745          0.7335   \n",
      "1930  0.0   0.620     0.490   0.160        1.0350          0.4400   \n",
      "1687  1.0   0.620     0.480   0.175        1.0405          0.4640   \n",
      "1641  0.0   0.575     0.445   0.160        0.8390          0.4005   \n",
      "2375  0.0   0.340     0.275   0.090        0.2065          0.0725   \n",
      "\n",
      "      Weight.viscera  Weight.shell  Rings  T  \n",
      "1170          0.2715         0.332      9  0  \n",
      "1930          0.2525         0.285     11  1  \n",
      "1687          0.2225         0.300      9  0  \n",
      "1641          0.1980         0.239      9  1  \n",
      "2375          0.0430         0.070     10  1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucile/causal_info_gain/causal_prospective_merge/rct_data_generator.py:145: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1.0 + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "#dictionnary of random sites\n",
    "candidate_sites = generating_random_sites_from(initial_data, exp_parameters)\n",
    "host = candidate_sites.popitem()[1]\n",
    "\n",
    "# Prior parameters for Bayesian update on host\n",
    "d = np.shape(host)[1]-1\n",
    "prior_mean = torch.zeros(d)\n",
    "sigma_prior = 1\n",
    "beta_0, sigma_0_sq, inv_cov_0 = prior_mean, sigma_rand_error,torch.eye(d)\n",
    "prior_hyperparameters = {'beta_0': beta_0, 'sigma_0_sq': sigma_0_sq,\"inv_cov_0\":inv_cov_0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "XandT_host, Y_host = torch.from_numpy(host.drop(columns=[\"Y\"]).values), torch.from_numpy(host[\"Y\"].values)\n",
    "n_samples_outer_expectation = 20\n",
    "n_samples_inner_expectation = 30\n",
    "results = {\"EIG_obs_from_samples\": [], 'EIG_caus_from_samples':[], \"EIG_obs_closed_form\":[], \"EIG_caus_closed_form\":[], \"EIG_obs_bart\":[], \"EIG_caus_bart\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a sample size of 209\n",
      " % treated in host: 77%\n",
      "For a sample size of 241\n",
      " % treated in host: 48%\n",
      "For a sample size of 230\n",
      " % treated in host: 50%\n",
      "For a sample size of 247\n",
      " % treated in host: 0%\n",
      "For a sample size of 176\n",
      " % treated in host: 51%\n",
      "For a sample size of 235\n",
      " % treated in host: 50%\n",
      "For a sample size of 208\n",
      " % treated in host: 51%\n",
      "For a sample size of 222\n",
      " % treated in host: 42%\n",
      "For a sample size of 178\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _,candidate \u001b[38;5;129;01min\u001b[39;00m candidate_sites\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor a sample size of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mshape(candidate)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m % treated in host: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m100\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39mcandidate[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "for _,candidate in candidate_sites.items():\n",
    "    print(f\"For a sample size of {np.shape(candidate)[0]}\")\n",
    "    print(f\" % treated in host: {int(100 * candidate['T'].mean())}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _,candidate in candidate_sites.items():\n",
    "    X_cand = torch.from_numpy(candidate.drop(columns=[\"Y\"]).values)\n",
    "    bayes_reg = BayesianLinearRegression(prior_hyperparameters)\n",
    "    bayes_reg.set_causal_index(causal_param_first_index)\n",
    "    post_host_parameters = bayes_reg.fit(XandT_host, Y_host)\n",
    "    n_samples = n_samples_outer_expectation * (n_samples_inner_expectation + 1)\n",
    "\n",
    "    results[\"EIG_obs_from_samples\"].append(\n",
    "            bayes_reg.samples_obs_EIG(\n",
    "                X_cand, n_samples_outer_expectation, n_samples_inner_expectation\n",
    "            )\n",
    "        )\n",
    "    results[\"EIG_caus_from_samples\"].append(\n",
    "            bayes_reg.samples_causal_EIG(\n",
    "                X_cand, n_samples_outer_expectation, n_samples_inner_expectation\n",
    "            )\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucile/causal_info_gain/pjake/lib/python3.9/site-packages/numpy/linalg/linalg.py:2094: RuntimeWarning: invalid value encountered in slogdet\n",
      "  sign, logdet = _umath_linalg.slogdet(a, signature=signature)\n"
     ]
    }
   ],
   "source": [
    "for _, candidate in candidate_sites.items():\n",
    "    X_cand = torch.from_numpy(candidate.drop(columns=[\"Y\"]).values)\n",
    "    bayes_reg = BayesianLinearRegression(prior_hyperparameters)\n",
    "    bayes_reg.set_causal_index(causal_param_first_index)\n",
    "    post_host_parameters = bayes_reg.fit(XandT_host, Y_host)\n",
    "    n_samples = n_samples_outer_expectation * (n_samples_inner_expectation + 1)\n",
    "\n",
    "    results[\"EIG_obs_closed_form\"].append(\n",
    "            bayes_reg.closed_form_obs_EIG(X_cand)\n",
    "            )\n",
    "    results[\"EIG_caus_closed_form\"].append(\n",
    "            bayes_reg.closed_form_causal_EIG(X_cand)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_host, T_host, Y_host = host.drop(columns=['T','Y']).values, host['T'].values, host['Y'].values\n",
    "\n",
    "beta_0, sigma_0_sq, inv_cov_0 = (\n",
    "    prior_mean,\n",
    "    sigma_rand_error**2,\n",
    "    1 / sigma_prior * np.eye(len(prior_mean)),\n",
    ")\n",
    "prior_hyperparameters = {\n",
    "    \"beta_0\": beta_0,\n",
    "    \"sigma_0_sq\": sigma_0_sq,\n",
    "    \"inv_cov_0\": inv_cov_0,\n",
    "}\n",
    "\n",
    "prior_hyperparameters = {'sigma_0_sq':1, 'p_categorical_pr':0, 'p_categorical_trt':0 }\n",
    "predictive_model_parameters={\"num_trees_pr\":200,\"num_trees_trt\":100}\n",
    "conditional_model_param={\"num_trees_pr\":200}\n",
    "\n",
    "for _, candidate in candidate_sites.items():\n",
    "\n",
    "    X_cand, T_cand = candidate.drop(columns=['Y','T']).values, candidate['T'].values\n",
    "\n",
    "    bcf = BayesianCausalForest(\n",
    "        prior_hyperparameters,\n",
    "        predictive_model_parameters=predictive_model_parameters,\n",
    "        conditional_model_param=conditional_model_param)\n",
    "    bcf.store_train_data(X=X_host, T=T_host, Y=Y_host)\n",
    "    \n",
    "    joint_eig = bcf.joint_EIG_calc(X_cand, T_cand, sampling_parameters)\n",
    "\n",
    "    EIG_obs[cand].append(joint_eig[\"Obs EIG\"])\n",
    "    EIG_caus[cand].append(joint_eig[\"Causal EIG\"])\n",
    "\n",
    "    joint_eig\n",
    "\n",
    "    results[\"EIG_obs_closed_form\"].append(\n",
    "            bayes_reg.closed_form_obs_EIG(X_cand)\n",
    "            )\n",
    "    results[\"EIG_caus_closed_form\"].append(\n",
    "            bayes_reg.closed_form_causal_EIG(X_cand)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now merge and compute some CATE error\n",
    "merged_datasets = {}\n",
    "\n",
    "for i, candidate in candidate_sites.items():\n",
    "    merged_datasets[i]= pd.concat([host, candidate], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATE_errors = {}\n",
    "merged_datasets = {}\n",
    "\n",
    "from econml.metalearners import TLearner\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "model_y = GradientBoostingRegressor()\n",
    "model_t = GradientBoostingClassifier()\n",
    "\n",
    "for i, candidate in merged_datasets.items():\n",
    "    merged_datasets[i]= pd.concat([host, candidate], axis=0)\n",
    "    X_merged = merged_datasets[i].filter(regex='^(?!T)').copy()\n",
    "    X_merged = X_merged.drop(columns=[\"Y\"])\n",
    "    T_merged = merged_datasets[i]['T']\n",
    "    Y_merged = merged_datasets[i]['Y']\n",
    "\n",
    "    learner = TLearner(model_y=model_y, model_t=model_t)\n",
    "    learner.fit(Y=Y_merged, T=T_merged, X=X_merged)\n",
    "    cate = learner.effect(X_merged)\n",
    "    ### need dataset with ground truth to compute some kind of errors here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pjake_kernel",
   "language": "python",
   "name": "pjake_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
