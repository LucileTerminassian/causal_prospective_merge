{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucile/causal_info_gain/pjake/lib/python3.9/site-packages/torch/__init__.py:696: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:453.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "torch.set_default_tensor_type(torch.FloatTensor) \n",
    "import copy\n",
    "import sys\n",
    "import os\n",
    "notebook_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(notebook_dir)\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(parent_dir)\n",
    "sys.path.append('/Users/lucile/causal_info_gain/causal_prospective_merge/data')\n",
    "\n",
    "from rct_data_generator import *\n",
    "from outcome_models import *\n",
    "from plotting_functions import *\n",
    "from mcmc_bayes_update import *\n",
    "from eig_comp_utils import *\n",
    "from research_exp_utils import *\n",
    "\n",
    "from econml.metalearners import TLearner\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eclamp</th>\n",
       "      <th>gestatcat1</th>\n",
       "      <th>gestatcat2</th>\n",
       "      <th>gestatcat3</th>\n",
       "      <th>gestatcat4</th>\n",
       "      <th>gestatcat5</th>\n",
       "      <th>gestatcat6</th>\n",
       "      <th>gestatcat7</th>\n",
       "      <th>gestatcat8</th>\n",
       "      <th>gestatcat9</th>\n",
       "      <th>...</th>\n",
       "      <th>brstate_reg</th>\n",
       "      <th>feduc6</th>\n",
       "      <th>dfageq</th>\n",
       "      <th>nprevistq</th>\n",
       "      <th>data_year</th>\n",
       "      <th>crace</th>\n",
       "      <th>birmon</th>\n",
       "      <th>dtotord_min</th>\n",
       "      <th>dlivord_min</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   eclamp  gestatcat1  gestatcat2  gestatcat3  gestatcat4  gestatcat5  \\\n",
       "0     0.0         0.0         1.0         1.0         0.0         1.0   \n",
       "1     0.0         0.0         1.0         1.0         0.0         0.0   \n",
       "2     0.0         0.0         1.0         0.0         1.0         0.0   \n",
       "3     0.0         0.0         0.0         0.0         1.0         0.0   \n",
       "4     0.0         0.0         1.0         1.0         0.0         0.0   \n",
       "\n",
       "   gestatcat6  gestatcat7  gestatcat8  gestatcat9  ...  brstate_reg  feduc6  \\\n",
       "0         1.0         0.0         0.0         1.0  ...          5.0     2.0   \n",
       "1         0.0         0.0         1.0         0.0  ...          5.0     5.0   \n",
       "2         0.0         0.0         0.0         1.0  ...          5.0     2.0   \n",
       "3         1.0         0.0         0.0         0.0  ...          5.0     4.0   \n",
       "4         0.0         0.0         0.0         0.0  ...          5.0     4.0   \n",
       "\n",
       "   dfageq  nprevistq  data_year  crace  birmon  dtotord_min  dlivord_min    T  \n",
       "0     1.0        0.0        0.0    0.0     0.0          3.0          3.0  1.0  \n",
       "1     8.0        0.0        0.0    0.0     0.0          1.0          1.0  1.0  \n",
       "2     0.0        0.0        0.0    0.0     0.0          1.0          1.0  0.0  \n",
       "3     6.0        0.0        0.0    0.0     0.0          2.0          2.0  1.0  \n",
       "4     7.0        0.0        0.0    1.0     0.0          3.0          3.0  0.0  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/lucile/causal_info_gain/causal_prospective_merge/'\n",
    "data_with_groundtruth, x, t, y = get_data('twins', path)\n",
    "data_with_groundtruth.dropna(inplace=True)\n",
    "data_with_groundtruth = data_with_groundtruth.rename(columns={'t': 'T', 'y': 'Y'})\n",
    "XandT = data_with_groundtruth.drop(columns=['Y','y0','y1','ite'])\n",
    "XandT.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_candidate_sites = 50\n",
    "min_sample_size_cand = 100\n",
    "max_sample_size_cand = 300\n",
    "host_sample_size = 200 #TODO fix (or not)\n",
    "desired_initial_sample_size = 10**4\n",
    "XandT = XandT.sample(n=desired_initial_sample_size, replace=True, random_state=42)\n",
    "\n",
    "outcome_function = None\n",
    "std_true_y = 1\n",
    "power_x = 1\n",
    "power_x_t = 1\n",
    "sigma_rand_error = 1\n",
    "\n",
    "exp_parameters = {'number_of_candidate_sites': number_of_candidate_sites+1, 'min_sample_size_cand': min_sample_size_cand, \\\n",
    "                'max_sample_size_cand': max_sample_size_cand, 'host_sample_size': host_sample_size, 'outcome_function': outcome_function, \\\n",
    "                'std_true_y': std_true_y, 'power_x': power_x, 'power_x_t': power_x_t}\n",
    "\n",
    "causal_param_first_index = causal_param_first_index = power_x * np.shape(XandT)[1] + 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_random_sites_from(data, exp_parameters, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    sites = {}\n",
    "    sample_size, number_covariates = np.shape(data)[0], np.shape(data)[1]\n",
    "    function_indices = {0: lambda X: np.log(X+1), 1: lambda X: X**3, 2: lambda X: X, 3: lambda X: X**2}\n",
    "    number_of_candidate_sites = exp_parameters['number_of_candidate_sites']\n",
    "    min_sample_size_cand = exp_parameters['min_sample_size_cand']\n",
    "    max_sample_size_cand = exp_parameters['max_sample_size_cand']\n",
    "    outcome_function = None\n",
    "    std_true_y = exp_parameters['std_true_y']\n",
    "    power_x = exp_parameters['power_x']\n",
    "    power_x_t = exp_parameters['power_x_t']\n",
    "    number_features = number_covariates\n",
    "    created_sites = 0\n",
    "    \n",
    "    while created_sites < number_of_candidate_sites:\n",
    "        \n",
    "        selected_features_for_subsampling = np.random.randint(2, size = number_features) \n",
    "        # binary bool vector representing selection for being an input of the sampling function\n",
    "        random_coefs = [np.random.uniform(-10, 10) for _ in range(number_features)] \n",
    "        random_fct_idx = [np.random.randint(0, 4) for _ in range(number_features)] \n",
    "        \n",
    "        def p_assigned_to_site(X, T, eps):\n",
    "            result = 0\n",
    "            for j in range(number_features-1):\n",
    "                result += selected_features_for_subsampling[j] * random_coefs[j] * function_indices[random_fct_idx[j]](X[j])\n",
    "            result += selected_features_for_subsampling[-1] * random_coefs[-1] *  function_indices[random_fct_idx[-1]](T)\n",
    "            return sigmoid(result + eps)\n",
    "        \n",
    "        sample_size = np.random.randint(min_sample_size_cand, max_sample_size_cand + 1)  # Add 1 to include max_sample_size_cand\n",
    "        design_data_cand = subsample_one_dataset(XandT, p_assigned_to_site, sample_size, power_x, power_x_t, outcome_function, std_true_y, seed=seed)\n",
    "        any_nan = design_data_cand.isna().any().any()\n",
    "        if not design_data_cand.empty and not any_nan:\n",
    "            sites[created_sites] = design_data_cand\n",
    "            created_sites += 1\n",
    "\n",
    "    return sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "#dictionnary of random sites\n",
    "candidate_sites = generating_random_sites_from(XandT, exp_parameters, seed=0)\n",
    "for i, cand in candidate_sites.items():\n",
    "    candidate_sites[i] = pd.concat([cand, data_with_groundtruth.loc[cand.index, 'Y']], axis=1)\n",
    "    \n",
    "host = candidate_sites.popitem()[1]\n",
    "\n",
    "# Prior parameters for Bayesian update on host\n",
    "d = np.shape(host)[1]-1\n",
    "prior_mean = torch.zeros(d)\n",
    "sigma_prior = 1\n",
    "beta_0, sigma_0_sq, inv_cov_0 = prior_mean, sigma_rand_error,torch.eye(d)\n",
    "prior_hyperparameters = {'beta_0': beta_0, 'sigma_0_sq': sigma_0_sq,\"inv_cov_0\":inv_cov_0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "XandT_host, Y_host = torch.from_numpy(host.drop(columns=[\"Y\"]).values), torch.from_numpy(host[\"Y\"].values)\n",
    "\n",
    "n_samples_outer_expectation_obs = 200\n",
    "n_samples_inner_expectation_obs = 400\n",
    "n_samples_outer_expectation_caus = 200\n",
    "n_samples_inner_expectation_caus = 400\n",
    "\n",
    "sampling_parameters = {'n_samples_inner_expectation_obs':n_samples_inner_expectation_obs, 'n_samples_outer_expectation_obs':n_samples_outer_expectation_obs, \\\n",
    "                       'n_samples_inner_expectation_caus':n_samples_inner_expectation_caus, 'n_samples_outer_expectation_caus':n_samples_outer_expectation_caus}\n",
    "\n",
    "results = {\"EIG_obs_from_samples\": [], 'EIG_caus_from_samples':[], \"EIG_obs_closed_form\":[], \"EIG_caus_closed_form\":[], \"EIG_obs_bart\":[], \"EIG_caus_bart\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a sample size of 102\n",
      " % treated in host: 66.67%\n",
      "For a sample size of 251\n",
      " % treated in host: 68.53%\n",
      "For a sample size of 183\n",
      " % treated in host: 67.21%\n",
      "For a sample size of 107\n",
      " % treated in host: 74.77%\n",
      "For a sample size of 125\n",
      " % treated in host: 70.4%\n",
      "For a sample size of 214\n",
      " % treated in host: 73.83%\n",
      "For a sample size of 201\n",
      " % treated in host: 71.64%\n",
      "For a sample size of 203\n",
      " % treated in host: 69.95%\n",
      "For a sample size of 112\n",
      " % treated in host: 75.0%\n",
      "For a sample size of 214\n",
      " % treated in host: 67.29%\n",
      "For a sample size of 275\n",
      " % treated in host: 77.82%\n",
      "For a sample size of 160\n",
      " % treated in host: 72.5%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n",
      "For a sample size of 113\n",
      " % treated in host: 73.45%\n"
     ]
    }
   ],
   "source": [
    "for _,candidate in candidate_sites.items():\n",
    "    print(f\"For a sample size of {np.shape(candidate)[0]}\")\n",
    "    print(f\" % treated in host: {round(100 * candidate['T'].mean(),2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, candidate in candidate_sites.items():\n",
    "    X_cand = torch.from_numpy(candidate.drop(columns=[\"Y\"]).values)\n",
    "    bayes_reg = BayesianLinearRegression(prior_hyperparameters)\n",
    "    bayes_reg.set_causal_index(causal_param_first_index)\n",
    "    post_host_parameters = bayes_reg.fit(XandT_host, Y_host)\n",
    "    n_samples = n_samples_outer_expectation_obs * (n_samples_inner_expectation_obs + 1)\n",
    "\n",
    "    results[\"EIG_obs_closed_form\"].append(\n",
    "            bayes_reg.closed_form_obs_EIG(X_cand)\n",
    "            )\n",
    "    results[\"EIG_caus_closed_form\"].append(\n",
    "            bayes_reg.closed_form_causal_EIG(X_cand)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, candidate in candidate_sites.items():\n",
    "    X_cand = torch.from_numpy(candidate.drop(columns=[\"Y\"]).values)\n",
    "    bayes_reg = BayesianLinearRegression(prior_hyperparameters)\n",
    "    bayes_reg.set_causal_index(causal_param_first_index)\n",
    "    post_host_parameters = bayes_reg.fit(XandT_host, Y_host)\n",
    "\n",
    "    results[\"EIG_obs_from_samples\"].append(\n",
    "            bayes_reg.samples_obs_EIG(\n",
    "                X_cand, n_samples_outer_expectation_obs, n_samples_inner_expectation_obs\n",
    "            )\n",
    "        )\n",
    "    results[\"EIG_caus_from_samples\"].append(\n",
    "            bayes_reg.samples_causal_EIG(\n",
    "                X_cand, n_samples_outer_expectation_obs, n_samples_inner_expectation_obs\n",
    "            )\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_host, T_host, Y_host = host.drop(columns=['T','Y']).values, host['T'].values.astype(np.int32), host['Y'].values\n",
    "\n",
    "# prior_hyperparameters = {'sigma_0_sq':1, 'p_categorical_pr':0, 'p_categorical_trt':0 }\n",
    "# predictive_model_parameters={\"num_trees_pr\":200,\"num_trees_trt\":100}\n",
    "# conditional_model_param={\"num_trees_pr\":200}\n",
    "\n",
    "\n",
    "# for _, candidate in candidate_sites.items():\n",
    "\n",
    "#     X_cand, T_cand = candidate.drop(columns=['Y','T']).values, candidate['T'].values.astype(np.int32)\n",
    "\n",
    "#     bcf = BayesianCausalForest(\n",
    "#         prior_hyperparameters,\n",
    "#         predictive_model_parameters=predictive_model_parameters,\n",
    "#         conditional_model_param=conditional_model_param)\n",
    "#     bcf.store_train_data(X=X_host, T=T_host, Y=Y_host)\n",
    "    \n",
    "#     joint_eig = bcf.joint_EIG_calc(X_cand, T_cand, sampling_parameters)\n",
    "\n",
    "#     results[\"EIG_obs_bart\"].append(joint_eig[\"Obs EIG\"])\n",
    "#     results[\"EIG_caus_bart\"].append(joint_eig[\"Causal EIG\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now merge and compute some CATE error\n",
    "merged_datasets = {}\n",
    "\n",
    "for i, candidate in candidate_sites.items():\n",
    "    merged_datasets[i]= pd.concat([host, candidate], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_diff = {}\n",
    "\n",
    "model_y = GradientBoostingRegressor()\n",
    "model_t = GradientBoostingClassifier()\n",
    "\n",
    "for i, candidate in merged_datasets.items():\n",
    "    \n",
    "    X_merged = merged_datasets[i].filter(regex='^(?!T)').copy()\n",
    "    X_merged = X_merged.drop(columns=[\"Y\"])\n",
    "    T_merged = merged_datasets[i]['T']\n",
    "    Y_merged = merged_datasets[i]['Y']\n",
    "\n",
    "    learner = TLearner(models= GradientBoostingRegressor())\n",
    "    learner.fit(Y=Y_merged, T=T_merged, X=X_merged)\n",
    "    cate = learner.effect(X_merged)\n",
    "    ### need dataset with ground truth to compute some kind of errors here\n",
    "    true_ite = data_with_groundtruth.loc[merged_datasets[i].index, 'ite']\n",
    "    cate_diff[i]=np.mean(abs(cate - true_ite.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 1, 9, 6, 7, 2, 5, 11, 8, 0, 4, 3, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[10, 9, 2, 6, 1, 7, 8, 0, 3, 4, 5, 11, 23, 49, 33, 13, 28, 32, 12, 31]\n",
      "[10, 4, 11, 1, 8, 2, 7, 5, 3, 9, 0, 6, 16, 41, 37, 13, 31, 47, 42, 45]\n"
     ]
    }
   ],
   "source": [
    "top_n = 20\n",
    "eig_ranking_closed_form = sorted(range(len(results[\"EIG_caus_closed_form\"])), key=lambda i: results[\"EIG_caus_closed_form\"][i], reverse=True)[:top_n]\n",
    "print(eig_ranking_closed_form)\n",
    "eig_ranking_from_samples = sorted(range(len(results[\"EIG_caus_from_samples\"])), key=lambda i: results[\"EIG_caus_from_samples\"][i], reverse=True)[:top_n]\n",
    "print(eig_ranking_from_samples)\n",
    "true_cate_ranking = sorted(cate_diff, key=cate_diff.get, reverse=True)[:top_n]\n",
    "print(true_cate_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kendalltau, spearmanr\n",
    "\n",
    "def average_precision_at_k(true_rankings, predicted_rankings, k):\n",
    "    num_hits = 0\n",
    "    sum_precision = 0\n",
    "    for i, pred in enumerate(predicted_rankings[:k], 1):\n",
    "        if pred in true_rankings:\n",
    "            num_hits += 1\n",
    "            sum_precision += num_hits / i\n",
    "    if not true_rankings:\n",
    "        return 0\n",
    "    return sum_precision / min(len(true_rankings), k)\n",
    "\n",
    "def mean_average_precision(true_rankings, predicted_rankings, k=None):\n",
    "    if k is None:\n",
    "        k = len(true_rankings)\n",
    "    avg_precision = np.mean([average_precision_at_k(true_rankings, predicted_rankings, k_) for k_ in range(1, k + 1)])\n",
    "    return avg_precision\n",
    "\n",
    "def precision_at_k(true_rankings, predicted_rankings, k):\n",
    "    intersection = set(predicted_rankings[:k]) & set(true_rankings)\n",
    "    return len(intersection) / k\n",
    "\n",
    "def recall_at_k(true_rankings, predicted_rankings, k):\n",
    "    intersection = set(predicted_rankings[:k]) & set(true_rankings)\n",
    "    return len(intersection) / len(true_rankings)\n",
    "\n",
    "# Mean Reciprocal Rank (MRR)\n",
    "def mrr(true_rankings, predicted_rankings):\n",
    "    for i, pred in enumerate(predicted_rankings, 1):\n",
    "        if pred in true_rankings:\n",
    "            return 1 / i\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tau_closed_form 0.631578947368421\n",
      "p_value_closed_form 3.6222609144151624e-05\n",
      "tau_from_samples 0.5578947368421052\n",
      "p_value_from_samples 0.00035899561704050146\n",
      "rho_closed_form 0.819548872180451\n",
      "rho_from_samples 0.7293233082706766\n",
      "Precision at K Closed Form for k= 20 is 0.7\n",
      "Precision at K From Samples for k= 20 is 0.7\n",
      "Recall at K Closed Form for k= 20 is 0.7\n",
      "Recall at K From Samples for k= 20 is 0.7\n",
      "Mean Average Precision Closed Form (MAP): 0.9250419660302797\n",
      "Mean Average Precision From Samples (MAP): 0.9098225080813365\n",
      "ndcg_closed_form 0.974812858996945\n",
      "ndcg_from_samples 0.956496732397278\n",
      "rank corr eig closed form 0.8227256827698197\n",
      "rank corr eig from samples 0.8291004918868893\n"
     ]
    }
   ],
   "source": [
    "k = 20\n",
    "\n",
    "tau_closed_form, p_value_closed_form = kendalltau(true_cate_ranking, eig_ranking_closed_form)\n",
    "print('tau_closed_form '+str(tau_closed_form))\n",
    "print('p_value_closed_form '+str(p_value_closed_form))\n",
    "\n",
    "tau_from_samples, p_value_from_samples = kendalltau(true_cate_ranking, eig_ranking_from_samples)\n",
    "print('tau_from_samples '+str(tau_from_samples))\n",
    "print('p_value_from_samples '+str(p_value_from_samples))\n",
    "\n",
    "rho_closed_form, _ = spearmanr(true_cate_ranking, eig_ranking_closed_form)\n",
    "print('rho_closed_form '+str(rho_closed_form))\n",
    "\n",
    "rho_from_samples, _ = spearmanr(true_cate_ranking, eig_ranking_from_samples)\n",
    "print('rho_from_samples '+str(rho_from_samples))\n",
    "\n",
    "print(\"Precision at K Closed Form for k=\", k, 'is', precision_at_k(true_cate_ranking, eig_ranking_closed_form, k=k))\n",
    "print(\"Precision at K From Samples for k=\", k, 'is', precision_at_k(true_cate_ranking, eig_ranking_from_samples, k=k))\n",
    "\n",
    "print(\"Recall at K Closed Form for k=\", k, 'is', recall_at_k(true_cate_ranking, eig_ranking_closed_form, k=k))\n",
    "print(\"Recall at K From Samples for k=\", k, 'is', recall_at_k(true_cate_ranking, eig_ranking_from_samples, k=k))\n",
    "\n",
    "print(\"Mean Average Precision Closed Form (MAP):\", mean_average_precision(true_cate_ranking, eig_ranking_closed_form, k=k))\n",
    "print(\"Mean Average Precision From Samples (MAP):\", mean_average_precision(true_cate_ranking, eig_ranking_from_samples, k=k))\n",
    "\n",
    "print('ndcg_closed_form '+str(ndcg_score([true_cate_ranking], [eig_ranking_closed_form])))\n",
    "print('ndcg_from_samples '+str(ndcg_score([true_cate_ranking], [eig_ranking_from_samples])))\n",
    "\n",
    "print('rank corr eig closed form '+ str(np.corrcoef(true_cate_ranking, eig_ranking_closed_form)[0, 1]))\n",
    "print('rank corr eig from samples '+ str(np.corrcoef(true_cate_ranking, eig_ranking_from_samples)[0, 1]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pjake_kernel",
   "language": "python",
   "name": "pjake_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
