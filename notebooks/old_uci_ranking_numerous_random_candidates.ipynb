{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucile/causal_info_gain/pjake/lib/python3.9/site-packages/torch/__init__.py:696: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:453.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "torch.set_default_tensor_type(torch.FloatTensor) \n",
    "import copy\n",
    "import sys\n",
    "import os\n",
    "notebook_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(notebook_dir)\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(parent_dir)\n",
    "sys.path.append('/Users/lucile/causal_info_gain/causal_prospective_merge/data')\n",
    "\n",
    "from rct_data_generator import *\n",
    "from outcome_models import *\n",
    "from plotting_functions import *\n",
    "from mcmc_bayes_update import *\n",
    "from eig_comp_utils import *\n",
    "from research_exp_utils import *\n",
    "\n",
    "from econml.metalearners import TLearner\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kendalltau, spearmanr\n",
    "\n",
    "def average_precision_at_k(true_rankings, predicted_rankings, k):\n",
    "    num_hits = 0\n",
    "    sum_precision = 0\n",
    "    for i, pred in enumerate(predicted_rankings[:k], 1):\n",
    "        if pred in true_rankings:\n",
    "            num_hits += 1\n",
    "            sum_precision += num_hits / i\n",
    "    if not true_rankings:\n",
    "        return 0\n",
    "    return sum_precision / min(len(true_rankings), k)\n",
    "\n",
    "def mean_average_precision(true_rankings, predicted_rankings, k=None):\n",
    "    if k is None:\n",
    "        k = len(true_rankings)\n",
    "    avg_precision = np.mean([average_precision_at_k(true_rankings, predicted_rankings, k_) for k_ in range(1, k + 1)])\n",
    "    return avg_precision\n",
    "\n",
    "def precision_at_k(true_rankings, predicted_rankings, k):\n",
    "    intersection = set(predicted_rankings[:k]) & set(true_rankings)\n",
    "    return len(intersection) / k\n",
    "\n",
    "def recall_at_k(true_rankings, predicted_rankings, k):\n",
    "    intersection = set(predicted_rankings[:k]) & set(true_rankings)\n",
    "    return len(intersection) / len(true_rankings)\n",
    "\n",
    "def mrr(true_rankings, predicted_rankings):\n",
    "    for i, pred in enumerate(predicted_rankings, 1):\n",
    "        if pred in true_rankings:\n",
    "            return 1 / i\n",
    "    return 0\n",
    "\n",
    "def ndcg(true_rankings, predicted_rankings, k=None):\n",
    "    if k is None:\n",
    "        k = len(true_rankings)\n",
    "    dcg = sum(2 ** true_rankings[i] - 1 / np.log2(i + 2) for i in range(k))\n",
    "    ideal_rankings = sorted(true_rankings, reverse=True)\n",
    "    ideal_dcg = sum(2 ** ideal_rankings[i] - 1 / np.log2(i + 2) for i in range(k))\n",
    "    return dcg / ideal_dcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eclamp</th>\n",
       "      <th>gestatcat1</th>\n",
       "      <th>gestatcat2</th>\n",
       "      <th>gestatcat3</th>\n",
       "      <th>gestatcat4</th>\n",
       "      <th>gestatcat5</th>\n",
       "      <th>gestatcat6</th>\n",
       "      <th>gestatcat7</th>\n",
       "      <th>gestatcat8</th>\n",
       "      <th>gestatcat9</th>\n",
       "      <th>...</th>\n",
       "      <th>brstate_reg</th>\n",
       "      <th>feduc6</th>\n",
       "      <th>dfageq</th>\n",
       "      <th>nprevistq</th>\n",
       "      <th>data_year</th>\n",
       "      <th>crace</th>\n",
       "      <th>birmon</th>\n",
       "      <th>dtotord_min</th>\n",
       "      <th>dlivord_min</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   eclamp  gestatcat1  gestatcat2  gestatcat3  gestatcat4  gestatcat5  \\\n",
       "0     0.0         0.0         1.0         1.0         0.0         1.0   \n",
       "1     0.0         0.0         1.0         1.0         0.0         0.0   \n",
       "2     0.0         0.0         1.0         0.0         1.0         0.0   \n",
       "3     0.0         0.0         0.0         0.0         1.0         0.0   \n",
       "4     0.0         0.0         1.0         1.0         0.0         0.0   \n",
       "\n",
       "   gestatcat6  gestatcat7  gestatcat8  gestatcat9  ...  brstate_reg  feduc6  \\\n",
       "0         1.0         0.0         0.0         1.0  ...          5.0     2.0   \n",
       "1         0.0         0.0         1.0         0.0  ...          5.0     5.0   \n",
       "2         0.0         0.0         0.0         1.0  ...          5.0     2.0   \n",
       "3         1.0         0.0         0.0         0.0  ...          5.0     4.0   \n",
       "4         0.0         0.0         0.0         0.0  ...          5.0     4.0   \n",
       "\n",
       "   dfageq  nprevistq  data_year  crace  birmon  dtotord_min  dlivord_min    T  \n",
       "0     1.0        0.0        0.0    0.0     0.0          3.0          3.0  1.0  \n",
       "1     8.0        0.0        0.0    0.0     0.0          1.0          1.0  1.0  \n",
       "2     0.0        0.0        0.0    0.0     0.0          1.0          1.0  0.0  \n",
       "3     6.0        0.0        0.0    0.0     0.0          2.0          2.0  1.0  \n",
       "4     7.0        0.0        0.0    1.0     0.0          3.0          3.0  0.0  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/lucile/causal_info_gain/causal_prospective_merge/'\n",
    "data_with_groundtruth, x, t, y = get_data('twins', path)\n",
    "data_with_groundtruth.dropna(inplace=True)\n",
    "data_with_groundtruth = data_with_groundtruth.rename(columns={'t': 'T', 'y': 'Y'})\n",
    "XandT = data_with_groundtruth.drop(columns=['Y','y0','y1','ite'])\n",
    "XandT.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_candidate_sites = 50\n",
    "min_sample_size_cand = 100\n",
    "max_sample_size_cand = 200\n",
    "host_sample_size = 200 \n",
    "desired_initial_sample_size = 10**4\n",
    "XandT = XandT.sample(n=desired_initial_sample_size, replace=True, random_state=42)\n",
    "\n",
    "outcome_function = None\n",
    "std_true_y = 1\n",
    "power_x = 1\n",
    "power_x_t = 1\n",
    "sigma_rand_error = 1\n",
    "\n",
    "exp_parameters = {'number_of_candidate_sites': number_of_candidate_sites+1, 'min_sample_size_cand': min_sample_size_cand, \\\n",
    "                'max_sample_size_cand': max_sample_size_cand, 'host_sample_size': host_sample_size, 'outcome_function': outcome_function, \\\n",
    "                'std_true_y': std_true_y, 'power_x': power_x, 'power_x_t': power_x_t}\n",
    "\n",
    "causal_param_first_index = causal_param_first_index = power_x * np.shape(XandT)[1] + 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_random_sites_from(data, exp_parameters):\n",
    "    \n",
    "    candidates = {}\n",
    "    sample_size, number_covariates = np.shape(data)[0], np.shape(data)[1]\n",
    "    function_indices = {0: lambda X: np.log(X+1), 1: lambda X: X**3, 2: lambda X: X, 3: lambda X: X**2}\n",
    "    number_of_candidate_sites = exp_parameters['number_of_candidate_sites']\n",
    "    min_sample_size_cand = exp_parameters['min_sample_size_cand']\n",
    "    max_sample_size_cand = exp_parameters['max_sample_size_cand']\n",
    "    outcome_function = None\n",
    "    std_true_y = exp_parameters['std_true_y']\n",
    "    power_x = exp_parameters['power_x']\n",
    "    power_x_t = exp_parameters['power_x_t']\n",
    "    number_features = number_covariates\n",
    "    created_sites = 0\n",
    "    \n",
    "    while created_sites < number_of_candidate_sites+1:\n",
    "\n",
    "        np.random.seed(created_sites)\n",
    "        \n",
    "        selected_features_for_subsampling = np.random.randint(2, size = number_features) \n",
    "        # binary bool vector representing selection for being an input of the sampling function\n",
    "        random_coefs = [np.random.uniform(-10, 10) for _ in range(number_features)] \n",
    "        random_fct_idx = [np.random.randint(0, 4) for _ in range(number_features)] \n",
    "        \n",
    "        def p_assigned_to_site(X, T, eps):\n",
    "            result = 0\n",
    "            for j in range(number_features-1):\n",
    "                result += selected_features_for_subsampling[j] * random_coefs[j] * function_indices[random_fct_idx[j]](X[j])\n",
    "            result += selected_features_for_subsampling[-1] * random_coefs[-1] *  function_indices[random_fct_idx[-1]](T)\n",
    "            return sigmoid(result + eps)\n",
    "        \n",
    "        sample_size = np.random.randint(min_sample_size_cand, max_sample_size_cand + 1)  # Add 1 to include max_sample_size_cand\n",
    "        if created_sites==0:\n",
    "            sample_size = exp_parameters['host_sample_size']\n",
    "        design_data_cand = subsample_one_dataset(XandT, p_assigned_to_site, sample_size, power_x, power_x_t, outcome_function, std_true_y, seed=created_sites)\n",
    "        any_nan = design_data_cand.isna().any().any()\n",
    "        if not design_data_cand.empty and not any_nan: # we're appending\n",
    "            candidates[created_sites] = design_data_cand\n",
    "        else:\n",
    "            number_of_candidate_sites+=1 # not appending\n",
    "        created_sites += 1\n",
    "\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "#dictionnary of random sites\n",
    "candidate_sites = generating_random_sites_from(XandT, exp_parameters)\n",
    "for i, cand in candidate_sites.items():\n",
    "    candidate_sites[i] = pd.concat([cand, data_with_groundtruth.loc[cand.index, 'Y']], axis=1)\n",
    "    \n",
    "host = candidate_sites[0]\n",
    "candidate_sites = {key: value for key, value in candidate_sites.items() if key != 0}\n",
    "XandT_host, Y_host = torch.from_numpy(host.drop(columns=[\"Y\"]).values), torch.from_numpy(host[\"Y\"].values)\n",
    "\n",
    "# Prior parameters for Bayesian update on host\n",
    "d = np.shape(host)[1]-1\n",
    "prior_mean = torch.zeros(d)\n",
    "sigma_prior = 1\n",
    "beta_0, sigma_0_sq, inv_cov_0 = prior_mean, sigma_rand_error,torch.eye(d)\n",
    "prior_hyperparameters = {'beta_0': beta_0, 'sigma_0_sq': sigma_0_sq,\"inv_cov_0\":inv_cov_0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_outer_expectation_obs = 400\n",
    "n_samples_inner_expectation_obs = 800\n",
    "n_samples_outer_expectation_caus = 400\n",
    "n_samples_inner_expectation_caus = 800\n",
    "\n",
    "sampling_parameters = {'n_samples_inner_expectation_obs':n_samples_inner_expectation_obs, 'n_samples_outer_expectation_obs':n_samples_outer_expectation_obs, \\\n",
    "                       'n_samples_inner_expectation_caus':n_samples_inner_expectation_caus, 'n_samples_outer_expectation_caus':n_samples_outer_expectation_caus}\n",
    "\n",
    "eig_results = {\"EIG_obs_from_samples\": [], 'EIG_caus_from_samples':[], \"EIG_obs_closed_form\":[], \"EIG_caus_closed_form\":[], \"EIG_obs_bart\":[], \"EIG_caus_bart\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a sample size of 200\n",
      " % treated in host: 71.0%\n",
      "For a sample size of 144\n",
      " % treated in host: 72.22%\n",
      "For a sample size of 182\n",
      " % treated in host: 68.13%\n",
      "For a sample size of 175\n",
      " % treated in host: 73.71%\n",
      "For a sample size of 195\n",
      " % treated in host: 71.79%\n",
      "For a sample size of 103\n",
      " % treated in host: 72.82%\n",
      "For a sample size of 124\n",
      " % treated in host: 76.61%\n",
      "For a sample size of 156\n",
      " % treated in host: 69.23%\n",
      "For a sample size of 184\n",
      " % treated in host: 70.11%\n",
      "For a sample size of 148\n",
      " % treated in host: 78.38%\n",
      "For a sample size of 104\n",
      " % treated in host: 68.27%\n",
      "For a sample size of 145\n",
      " % treated in host: 65.52%\n",
      "For a sample size of 122\n",
      " % treated in host: 68.03%\n",
      "For a sample size of 133\n",
      " % treated in host: 67.67%\n",
      "For a sample size of 198\n",
      " % treated in host: 69.7%\n",
      "For a sample size of 139\n",
      " % treated in host: 76.26%\n",
      "For a sample size of 137\n",
      " % treated in host: 70.8%\n",
      "For a sample size of 177\n",
      " % treated in host: 68.93%\n",
      "For a sample size of 137\n",
      " % treated in host: 72.99%\n",
      "For a sample size of 153\n",
      " % treated in host: 71.9%\n",
      "For a sample size of 104\n",
      " % treated in host: 69.23%\n",
      "For a sample size of 115\n",
      " % treated in host: 73.91%\n",
      "For a sample size of 130\n",
      " % treated in host: 72.31%\n",
      "For a sample size of 160\n",
      " % treated in host: 71.25%\n",
      "For a sample size of 178\n",
      " % treated in host: 67.42%\n",
      "For a sample size of 180\n",
      " % treated in host: 70.0%\n",
      "For a sample size of 123\n",
      " % treated in host: 68.29%\n",
      "For a sample size of 185\n",
      " % treated in host: 69.73%\n",
      "For a sample size of 128\n",
      " % treated in host: 70.31%\n",
      "For a sample size of 193\n",
      " % treated in host: 71.5%\n",
      "For a sample size of 146\n",
      " % treated in host: 70.55%\n",
      "For a sample size of 119\n",
      " % treated in host: 83.19%\n",
      "For a sample size of 125\n",
      " % treated in host: 68.0%\n",
      "For a sample size of 134\n",
      " % treated in host: 72.39%\n",
      "For a sample size of 137\n",
      " % treated in host: 71.53%\n",
      "For a sample size of 112\n",
      " % treated in host: 77.68%\n",
      "For a sample size of 141\n",
      " % treated in host: 70.92%\n",
      "For a sample size of 120\n",
      " % treated in host: 70.0%\n",
      "For a sample size of 107\n",
      " % treated in host: 67.29%\n",
      "For a sample size of 133\n",
      " % treated in host: 70.68%\n",
      "For a sample size of 162\n",
      " % treated in host: 76.54%\n",
      "For a sample size of 122\n",
      " % treated in host: 77.05%\n",
      "For a sample size of 101\n",
      " % treated in host: 67.33%\n",
      "For a sample size of 157\n",
      " % treated in host: 70.7%\n",
      "For a sample size of 186\n",
      " % treated in host: 68.82%\n",
      "For a sample size of 131\n",
      " % treated in host: 74.81%\n",
      "For a sample size of 130\n",
      " % treated in host: 70.0%\n",
      "For a sample size of 167\n",
      " % treated in host: 71.86%\n",
      "For a sample size of 111\n",
      " % treated in host: 70.27%\n",
      "For a sample size of 162\n",
      " % treated in host: 69.14%\n",
      "For a sample size of 124\n",
      " % treated in host: 75.0%\n",
      "For a sample size of 182\n",
      " % treated in host: 78.02%\n"
     ]
    }
   ],
   "source": [
    "for _,candidate in candidate_sites.items():\n",
    "    print(f\"For a sample size of {np.shape(candidate)[0]}\")\n",
    "    print(f\" % treated in host: {round(100 * candidate['T'].mean(),2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_results[\"EIG_obs_closed_form\"]=[]\n",
    "eig_results[\"EIG_caus_closed_form\"]=[]\n",
    "\n",
    "for _, candidate in candidate_sites.items():\n",
    "    X_cand = torch.from_numpy(candidate.drop(columns=[\"Y\"]).values)\n",
    "    bayes_reg = BayesianLinearRegression(prior_hyperparameters)\n",
    "    bayes_reg.set_causal_index(causal_param_first_index)\n",
    "    post_host_parameters = bayes_reg.fit(XandT_host, Y_host)\n",
    "    n_samples = n_samples_outer_expectation_obs * (n_samples_inner_expectation_obs + 1)\n",
    "\n",
    "    eig_results[\"EIG_obs_closed_form\"].append(\n",
    "            bayes_reg.closed_form_obs_EIG(X_cand)\n",
    "            )\n",
    "    eig_results[\"EIG_caus_closed_form\"].append(\n",
    "            bayes_reg.closed_form_causal_EIG(X_cand)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eig_results[\"EIG_obs_from_samples\"]=[]\n",
    "# eig_results[\"EIG_caus_from_samples\"]=[]\n",
    "\n",
    "# for _, candidate in candidate_sites.items():\n",
    "#     X_cand = torch.from_numpy(candidate.drop(columns=[\"Y\"]).values)\n",
    "#     bayes_reg = BayesianLinearRegression(prior_hyperparameters)\n",
    "#     bayes_reg.set_causal_index(causal_param_first_index)\n",
    "#     post_host_parameters = bayes_reg.fit(XandT_host, Y_host)\n",
    "\n",
    "#     eig_results[\"EIG_obs_from_samples\"].append(\n",
    "#             bayes_reg.samples_obs_EIG(\n",
    "#                 X_cand, n_samples_outer_expectation_obs, n_samples_inner_expectation_obs\n",
    "#             )\n",
    "#         )\n",
    "#     eig_results[\"EIG_caus_from_samples\"].append(\n",
    "#             bayes_reg.samples_causal_EIG(\n",
    "#                 X_cand, n_samples_outer_expectation_obs, n_samples_inner_expectation_obs\n",
    "#             )\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_host, T_host, Y_host = host.drop(columns=['T','Y']).values, host['T'].values.astype(np.int32), host['Y'].values\n",
    "\n",
    "# prior_hyperparameters = {'sigma_0_sq':1, 'p_categorical_pr':0, 'p_categorical_trt':0 }\n",
    "# predictive_model_parameters={\"num_trees_pr\":200,\"num_trees_trt\":100}\n",
    "# conditional_model_param={\"num_trees_pr\":200}\n",
    "\n",
    "\n",
    "# for _, candidate in candidate_sites.items():\n",
    "\n",
    "#     X_cand, T_cand = candidate.drop(columns=['Y','T']).values, candidate['T'].values.astype(np.int32)\n",
    "\n",
    "#     bcf = BayesianCausalForest(\n",
    "#         prior_hyperparameters,\n",
    "#         predictive_model_parameters=predictive_model_parameters,\n",
    "#         conditional_model_param=conditional_model_param)\n",
    "#     bcf.store_train_data(X=X_host, T=T_host, Y=Y_host)\n",
    "    \n",
    "#     joint_eig = bcf.joint_EIG_calc(X_cand, T_cand, sampling_parameters)\n",
    "\n",
    "#     results[\"EIG_obs_bart\"].append(joint_eig[\"Obs EIG\"])\n",
    "#     results[\"EIG_caus_bart\"].append(joint_eig[\"Causal EIG\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now merge and compute some CATE error\n",
    "merged_datasets = {}\n",
    "\n",
    "for i, candidate in candidate_sites.items():\n",
    "    merged_datasets[i]= pd.concat([host, candidate], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_diff = {}\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model_y = GradientBoostingRegressor()\n",
    "model_t = GradientBoostingClassifier()\n",
    "\n",
    "for i, candidate in merged_datasets.items():\n",
    "    \n",
    "    X_merged = merged_datasets[i].filter(regex='^(?!T)').copy()\n",
    "    X_merged = X_merged.drop(columns=[\"Y\"])\n",
    "    T_merged = merged_datasets[i]['T']\n",
    "    Y_merged = merged_datasets[i]['Y']\n",
    "\n",
    "    learner = TLearner(models= GradientBoostingRegressor())\n",
    "    learner.fit(Y=Y_merged, T=T_merged, X=X_merged)\n",
    "    pred_cate = learner.effect(X_merged)\n",
    "    ### need dataset with ground truth to compute some kind of errors here\n",
    "    true_cate = data_with_groundtruth.loc[merged_datasets[i].index, 'ite']\n",
    "    pred_cate\n",
    "    cate_diff[i]= - mean_squared_error(true_cate, pred_cate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 51, 14, 27, 44, 29, 25, 4, 2, 17, 11, 49, 7, 23, 43, 36, 19, 8, 24, 18, 9, 1, 30, 15, 28, 16, 34, 39, 22, 33]\n",
      "[3, 11, 25, 14, 27, 44, 51, 2, 17, 29, 4, 49, 7, 23, 36, 24, 43, 28, 19, 18, 8, 9, 30, 1, 46, 15, 16, 34, 39, 22]\n",
      "[36, 41, 51, 9, 24, 46, 25, 6, 21, 19, 39, 47, 34, 40, 20, 33, 22, 28, 18, 52, 13, 29, 43, 23, 16, 50, 42, 1, 12, 8]\n"
     ]
    }
   ],
   "source": [
    "top_n = 30\n",
    "obs_eig_ranking_closed_form = sorted(range(len(eig_results[\"EIG_obs_closed_form\"])), key=lambda i: eig_results[\"EIG_obs_closed_form\"][i], reverse=True)[:top_n]\n",
    "print(obs_eig_ranking_closed_form)\n",
    "caus_eig_ranking_closed_form = sorted(range(len(eig_results[\"EIG_caus_closed_form\"])), key=lambda i: eig_results[\"EIG_caus_closed_form\"][i], reverse=True)[:top_n]\n",
    "print(caus_eig_ranking_closed_form)\n",
    "# eig_ranking_from_samples = sorted(range(len(eig_results[\"EIG_caus_from_samples\"])), key=lambda i: eig_results[\"EIG_caus_from_samples\"][i], reverse=True)[:top_n]\n",
    "# print(eig_ranking_from_samples)\n",
    "true_cate_ranking = sorted(cate_diff, key=cate_diff.get, reverse=True)[:top_n]\n",
    "print(true_cate_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau</th>\n",
       "      <th>rho</th>\n",
       "      <th>precision_at_k</th>\n",
       "      <th>recall_at_k</th>\n",
       "      <th>mean average precision</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>rank corr eig</th>\n",
       "      <th>mean reciprocal rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>caus_closed_form</th>\n",
       "      <td>0.002299</td>\n",
       "      <td>-0.007786</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.064317</td>\n",
       "      <td>0.286633</td>\n",
       "      <td>-0.02222</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       tau       rho  precision_at_k  recall_at_k  \\\n",
       "caus_closed_form  0.002299 -0.007786             0.3          0.1   \n",
       "\n",
       "                  mean average precision      ndcg  rank corr eig  \\\n",
       "caus_closed_form                0.064317  0.286633       -0.02222   \n",
       "\n",
       "                  mean reciprocal rank  \n",
       "caus_closed_form              0.333333  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 10\n",
    "\n",
    "tau_closed_form, p_value_tau_closed_form = kendalltau(true_cate_ranking, caus_eig_ranking_closed_form)\n",
    "rho_closed_form, p_value_rho_closed_form = spearmanr(true_cate_ranking, caus_eig_ranking_closed_form)\n",
    "precision_at_k_closed_form = precision_at_k(true_cate_ranking, caus_eig_ranking_closed_form, k=k)\n",
    "recall_at_k_closed_form = recall_at_k(true_cate_ranking, caus_eig_ranking_closed_form, k=k)\n",
    "map_closed_form = mean_average_precision(true_cate_ranking, caus_eig_ranking_closed_form, k=k)\n",
    "ndcg_closed_form = ndcg(true_cate_ranking, caus_eig_ranking_closed_form, k)\n",
    "rank_corr_closed_form = np.corrcoef(true_cate_ranking, caus_eig_ranking_closed_form)[0, 1]\n",
    "mrr_closed_form = mrr(true_cate_ranking, caus_eig_ranking_closed_form)\n",
    "\n",
    "\n",
    "# tau_from_samples, p_value_tau_from_samples = kendalltau(true_cate_ranking, eig_ranking_from_samples)\n",
    "# rho_from_samples, p_value_rho_from_samples = spearmanr(true_cate_ranking, eig_ranking_from_samples)\n",
    "# precision_at_k_from_samples = precision_at_k(true_cate_ranking, eig_ranking_from_samples, k=k)\n",
    "# recall_at_k_from_samples = recall_at_k(true_cate_ranking, eig_ranking_from_samples, k=k)\n",
    "# map_from_samples = mean_average_precision(true_cate_ranking, eig_ranking_from_samples, k=k)\n",
    "# ndcg_from_samples = ndcg(true_cate_ranking, eig_ranking_from_samples, k)\n",
    "# rank_corr_from_samples = np.corrcoef(true_cate_ranking, eig_ranking_from_samples)[0, 1]\n",
    "# mrr_from_samples = mrr(true_cate_ranking, eig_ranking_from_samples)\n",
    "\n",
    "\n",
    "\n",
    "correlation_with_true_rankings={'tau':[tau_closed_form],'rho':[rho_closed_form], \\\n",
    "      'precision_at_k': [precision_at_k_closed_form], \\\n",
    "      'recall_at_k':[recall_at_k_closed_form], \\\n",
    "      'mean average precision': [map_closed_form], \n",
    "      'ndcg': [ndcg_closed_form], \\\n",
    "      'rank corr eig': [rank_corr_closed_form], \\\n",
    "      \"mean reciprocal rank\": [mrr_closed_form]}\n",
    "\n",
    "correlation_with_true_rankings= pd.DataFrame.from_dict(correlation_with_true_rankings)\n",
    "correlation_with_true_rankings.index = ['caus_closed_form']\n",
    "correlation_with_true_rankings\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pjake_kernel",
   "language": "python",
   "name": "pjake_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
