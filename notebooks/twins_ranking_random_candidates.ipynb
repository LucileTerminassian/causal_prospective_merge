{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucile/causal_info_gain/pjake/lib/python3.9/site-packages/torch/__init__.py:696: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:453.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "torch.set_default_tensor_type(torch.FloatTensor) \n",
    "import copy\n",
    "import sys\n",
    "import os\n",
    "notebook_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(notebook_dir)\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(parent_dir)\n",
    "sys.path.append('/Users/lucile/causal_info_gain/causal_prospective_merge/data')\n",
    "\n",
    "from rct_data_generator import *\n",
    "from outcome_models import *\n",
    "from plotting_functions import *\n",
    "from mcmc_bayes_update import *\n",
    "from eig_comp_utils import *\n",
    "from research_exp_utils import *\n",
    "\n",
    "from econml.metalearners import TLearner\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kendalltau, spearmanr\n",
    "\n",
    "def average_precision_at_k(true_rankings, predicted_rankings, k):\n",
    "    num_hits = 0\n",
    "    sum_precision = 0\n",
    "    for i, pred in enumerate(predicted_rankings[:k], 1):\n",
    "        if pred in true_rankings:\n",
    "            num_hits += 1\n",
    "            sum_precision += num_hits / i\n",
    "    if not true_rankings:\n",
    "        return 0\n",
    "    return sum_precision / min(len(true_rankings), k)\n",
    "\n",
    "def mean_average_precision(true_rankings, predicted_rankings, k=None):\n",
    "    if k is None:\n",
    "        k = len(true_rankings)\n",
    "    avg_precision = np.mean([average_precision_at_k(true_rankings, predicted_rankings, k_) for k_ in range(1, k + 1)])\n",
    "    return avg_precision\n",
    "\n",
    "def precision_at_k(true_rankings, predicted_rankings, k):\n",
    "    intersection = set(predicted_rankings[:k]) & set(true_rankings)\n",
    "    return len(intersection) / k\n",
    "\n",
    "def recall_at_k(true_rankings, predicted_rankings, k):\n",
    "    intersection = set(predicted_rankings[:k]) & set(true_rankings)\n",
    "    return len(intersection) / len(true_rankings)\n",
    "\n",
    "def mrr(true_rankings, predicted_rankings):\n",
    "    for i, pred in enumerate(predicted_rankings, 1):\n",
    "        if pred in true_rankings:\n",
    "            return 1 / i\n",
    "    return 0\n",
    "\n",
    "def ndcg(true_rankings, predicted_rankings, k=None):\n",
    "    if k is None:\n",
    "        k = len(true_rankings)\n",
    "    dcg = sum(2 ** true_rankings[i] - 1 / np.log2(i + 2) for i in range(k))\n",
    "    ideal_rankings = sorted(true_rankings, reverse=True)\n",
    "    ideal_dcg = sum(2 ** ideal_rankings[i] - 1 / np.log2(i + 2) for i in range(k))\n",
    "    return dcg / ideal_dcg\n",
    "\n",
    "def compare_to_ground_truth(results_dict, true_cate_ranking, eig_ranking, top_n = None, k = None):\n",
    "    \n",
    "    if top_n is not None:\n",
    "        topn_eig_ranking = eig_ranking[:top_n]\n",
    "        topn_true_cate_ranking = true_cate_ranking[:top_n]\n",
    "    else: \n",
    "        topn_eig_ranking, topn_true_cate_ranking = eig_ranking, true_cate_ranking\n",
    "\n",
    "    if k is None:\n",
    "        k = len(true_cate_ranking)\n",
    "    \n",
    "    results_dict['tau'].append(kendalltau(topn_eig_ranking, topn_true_cate_ranking)[0])      \n",
    "    results_dict['rho'].append(spearmanr(topn_true_cate_ranking, topn_eig_ranking)[0])\n",
    "    results_dict['precision_at_k'].append(precision_at_k(true_cate_ranking, topn_eig_ranking, k=k))\n",
    "    results_dict['recall_at_k'].append(recall_at_k(true_cate_ranking, topn_eig_ranking, k=k))\n",
    "    results_dict['mean average precision'].append(mean_average_precision(topn_true_cate_ranking, topn_eig_ranking, k=k))\n",
    "    results_dict['ndcg'].append(ndcg(topn_true_cate_ranking, topn_eig_ranking, k))\n",
    "    results_dict['rank corr eig'].append(np.corrcoef(topn_true_cate_ranking, topn_eig_ranking)[0, 1])\n",
    "    results_dict['mean reciprocal rank'].append(mrr(topn_true_cate_ranking, topn_eig_ranking))\n",
    "\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eclamp</th>\n",
       "      <th>gestatcat1</th>\n",
       "      <th>gestatcat2</th>\n",
       "      <th>gestatcat3</th>\n",
       "      <th>gestatcat4</th>\n",
       "      <th>gestatcat5</th>\n",
       "      <th>gestatcat6</th>\n",
       "      <th>gestatcat7</th>\n",
       "      <th>gestatcat8</th>\n",
       "      <th>gestatcat9</th>\n",
       "      <th>...</th>\n",
       "      <th>brstate_reg</th>\n",
       "      <th>feduc6</th>\n",
       "      <th>dfageq</th>\n",
       "      <th>nprevistq</th>\n",
       "      <th>data_year</th>\n",
       "      <th>crace</th>\n",
       "      <th>birmon</th>\n",
       "      <th>dtotord_min</th>\n",
       "      <th>dlivord_min</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   eclamp  gestatcat1  gestatcat2  gestatcat3  gestatcat4  gestatcat5  \\\n",
       "0     0.0         0.0         1.0         1.0         0.0         1.0   \n",
       "1     0.0         0.0         1.0         1.0         0.0         0.0   \n",
       "2     0.0         0.0         1.0         0.0         1.0         0.0   \n",
       "3     0.0         0.0         0.0         0.0         1.0         0.0   \n",
       "4     0.0         0.0         1.0         1.0         0.0         0.0   \n",
       "\n",
       "   gestatcat6  gestatcat7  gestatcat8  gestatcat9  ...  brstate_reg  feduc6  \\\n",
       "0         1.0         0.0         0.0         1.0  ...          5.0     2.0   \n",
       "1         0.0         0.0         1.0         0.0  ...          5.0     5.0   \n",
       "2         0.0         0.0         0.0         1.0  ...          5.0     2.0   \n",
       "3         1.0         0.0         0.0         0.0  ...          5.0     4.0   \n",
       "4         0.0         0.0         0.0         0.0  ...          5.0     4.0   \n",
       "\n",
       "   dfageq  nprevistq  data_year  crace  birmon  dtotord_min  dlivord_min    T  \n",
       "0     1.0        0.0        0.0    0.0     0.0          3.0          3.0  1.0  \n",
       "1     8.0        0.0        0.0    0.0     0.0          1.0          1.0  1.0  \n",
       "2     0.0        0.0        0.0    0.0     0.0          1.0          1.0  0.0  \n",
       "3     6.0        0.0        0.0    0.0     0.0          2.0          2.0  1.0  \n",
       "4     7.0        0.0        0.0    1.0     0.0          3.0          3.0  0.0  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/lucile/causal_info_gain/causal_prospective_merge/'\n",
    "data_with_groundtruth, x, t, y = get_data('twins', path)\n",
    "data_with_groundtruth.dropna(inplace=True)\n",
    "data_with_groundtruth = data_with_groundtruth.rename(columns={'t': 'T', 'y': 'Y'})\n",
    "XandT = data_with_groundtruth.drop(columns=['Y','y0','y1','ite'])\n",
    "XandT.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_candidate_sites = 40\n",
    "\n",
    "min_sample_size_cand = 50\n",
    "max_sample_size_cand = 150\n",
    "host_sample_size = 100 \n",
    "desired_initial_sample_size = 10**4\n",
    "XandT = XandT.sample(n=desired_initial_sample_size, replace=True, random_state=42)\n",
    "added_T_coef = 50 # to increase importance of T\n",
    "\n",
    "outcome_function = None\n",
    "std_true_y = 1\n",
    "power_x = 1\n",
    "power_x_t = 1\n",
    "sigma_rand_error = 1\n",
    "\n",
    "exp_parameters = {'number_of_candidate_sites': number_of_candidate_sites+1, 'min_sample_size_cand': min_sample_size_cand, \\\n",
    "                'max_sample_size_cand': max_sample_size_cand, 'host_sample_size': host_sample_size, 'outcome_function': outcome_function, \\\n",
    "                'std_true_y': std_true_y, 'power_x': power_x, 'power_x_t': power_x_t}\n",
    "\n",
    "causal_param_first_index = power_x*np.shape(XandT)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_random_sites_from(data, exp_parameters, added_T_coef=1):\n",
    "    \n",
    "    candidates = {}\n",
    "    sample_size, number_covariates = np.shape(data)[0], np.shape(data)[1]\n",
    "    function_indices = {0: lambda X: np.log(X+1), 1: lambda X: X**3, 2: lambda X: X, 3: lambda X: X**2 }\n",
    "    number_of_candidate_sites = exp_parameters['number_of_candidate_sites']\n",
    "    min_sample_size_cand = exp_parameters['min_sample_size_cand']\n",
    "    max_sample_size_cand = exp_parameters['max_sample_size_cand']\n",
    "    outcome_function = None\n",
    "    std_true_y = exp_parameters['std_true_y']\n",
    "    power_x = exp_parameters['power_x']\n",
    "    power_x_t = exp_parameters['power_x_t']\n",
    "    number_features = number_covariates\n",
    "    created_sites = 0\n",
    "    \n",
    "    while created_sites < number_of_candidate_sites+1:\n",
    "\n",
    "        np.random.seed(created_sites)\n",
    "        \n",
    "        selected_features_for_subsampling = np.random.randint(2, size = number_features) \n",
    "        # binary bool vector representing selection for being an input of the sampling function\n",
    "        random_coefs = [np.random.uniform(-10, 10) for _ in range(number_features)] \n",
    "        random_fct_idx = [np.random.randint(0, len(function_indices.keys())) for _ in range(number_features)] \n",
    "        \n",
    "        def p_assigned_to_site(X, T, eps):\n",
    "            result = 0\n",
    "            for j in range(number_features-1):\n",
    "                result += selected_features_for_subsampling[j] * random_coefs[j] * function_indices[random_fct_idx[j]](X[j])\n",
    "            # here i use added_T_coef * random_coefs to increase importance of T\n",
    "            result +=  added_T_coef * random_coefs[-1] *  function_indices[random_fct_idx[-1]](T) #selected_features_for_subsampling[-1]\n",
    "            return sigmoid(result + eps)\n",
    "        \n",
    "        sample_size = np.random.randint(min_sample_size_cand, max_sample_size_cand + 1)  # Add 1 to include max_sample_size_cand\n",
    "\n",
    "        if created_sites==0:\n",
    "            sample_size = exp_parameters['host_sample_size']\n",
    "        design_data_cand = subsample_one_dataset(XandT, p_assigned_to_site, sample_size, power_x, power_x_t, outcome_function, std_true_y, seed=created_sites)\n",
    "        any_nan = design_data_cand.isna().any().any()\n",
    "        if not design_data_cand.empty and not any_nan: # we're appending\n",
    "            candidates[created_sites] = design_data_cand\n",
    "        else:\n",
    "            number_of_candidate_sites+=1 # not appending\n",
    "        created_sites += 1\n",
    "\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "#dictionnary of random sites\n",
    "candidate_sites = generating_random_sites_from(XandT, exp_parameters, added_T_coef=50)\n",
    "for i, cand in candidate_sites.items():\n",
    "    candidate_sites[i] = pd.concat([cand, data_with_groundtruth.loc[cand.index, 'Y']], axis=1)\n",
    "    \n",
    "host = candidate_sites[0]\n",
    "candidate_sites = {key: value for key, value in candidate_sites.items() if key != 0}\n",
    "XandT_host, Y_host = torch.from_numpy(host.drop(columns=[\"Y\"]).values), torch.from_numpy(host[\"Y\"].values)\n",
    "\n",
    "# Prior parameters for Bayesian update on host\n",
    "d = np.shape(host)[1]-1\n",
    "prior_mean = torch.zeros(d)\n",
    "sigma_prior = 1\n",
    "beta_0, sigma_0_sq, inv_cov_0 = prior_mean, sigma_rand_error,torch.eye(d)\n",
    "prior_hyperparameters = {'beta_0': beta_0, 'sigma_0_sq': sigma_0_sq,\"inv_cov_0\":inv_cov_0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_outer_expectation_obs = 400\n",
    "n_samples_inner_expectation_obs = 800\n",
    "n_samples_outer_expectation_caus = 400\n",
    "n_samples_inner_expectation_caus = 800\n",
    "\n",
    "sampling_parameters = {'n_samples_inner_expectation_obs':n_samples_inner_expectation_obs, 'n_samples_outer_expectation_obs':n_samples_outer_expectation_obs, \\\n",
    "                       'n_samples_inner_expectation_caus':n_samples_inner_expectation_caus, 'n_samples_outer_expectation_caus':n_samples_outer_expectation_caus}\n",
    "\n",
    "eig_results = {\"EIG_obs_from_samples\": [], 'EIG_caus_from_samples':[], \"EIG_obs_closed_form\":[], \"EIG_caus_closed_form\":[], \"EIG_obs_bart\":[], \"EIG_caus_bart\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " % treated in host: 33.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\" % treated in host: {round(100 * host['T'].mean(),2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a sample size of 94\n",
      " % treated in candidate: 72.34%\n",
      "For a sample size of 132\n",
      " % treated in candidate: 66.67%\n",
      "For a sample size of 125\n",
      " % treated in candidate: 70.4%\n",
      "For a sample size of 145\n",
      " % treated in candidate: 57.93%\n",
      "For a sample size of 53\n",
      " % treated in candidate: 5.66%\n",
      "For a sample size of 74\n",
      " % treated in candidate: 86.49%\n",
      "For a sample size of 106\n",
      " % treated in candidate: 70.75%\n",
      "For a sample size of 134\n",
      " % treated in candidate: 0.0%\n",
      "For a sample size of 98\n",
      " % treated in candidate: 94.9%\n",
      "For a sample size of 54\n",
      " % treated in candidate: 25.93%\n",
      "For a sample size of 95\n",
      " % treated in candidate: 89.47%\n",
      "For a sample size of 72\n",
      " % treated in candidate: 58.33%\n",
      "For a sample size of 83\n",
      " % treated in candidate: 53.01%\n",
      "For a sample size of 148\n",
      " % treated in candidate: 68.92%\n",
      "For a sample size of 89\n",
      " % treated in candidate: 77.53%\n",
      "For a sample size of 87\n",
      " % treated in candidate: 42.53%\n",
      "For a sample size of 127\n",
      " % treated in candidate: 72.44%\n",
      "For a sample size of 103\n",
      " % treated in candidate: 71.84%\n",
      "For a sample size of 54\n",
      " % treated in candidate: 57.41%\n",
      "For a sample size of 65\n",
      " % treated in candidate: 73.85%\n",
      "For a sample size of 80\n",
      " % treated in candidate: 75.0%\n",
      "For a sample size of 110\n",
      " % treated in candidate: 69.09%\n",
      "For a sample size of 128\n",
      " % treated in candidate: 0.0%\n",
      "For a sample size of 130\n",
      " % treated in candidate: 0.0%\n",
      "For a sample size of 73\n",
      " % treated in candidate: 71.23%\n",
      "For a sample size of 135\n",
      " % treated in candidate: 71.85%\n",
      "For a sample size of 78\n",
      " % treated in candidate: 0.0%\n",
      "For a sample size of 143\n",
      " % treated in candidate: 74.83%\n",
      "For a sample size of 96\n",
      " % treated in candidate: 77.08%\n",
      "For a sample size of 69\n",
      " % treated in candidate: 98.55%\n",
      "For a sample size of 75\n",
      " % treated in candidate: 70.67%\n",
      "For a sample size of 84\n",
      " % treated in candidate: 63.1%\n",
      "For a sample size of 87\n",
      " % treated in candidate: 60.92%\n",
      "For a sample size of 62\n",
      " % treated in candidate: 93.55%\n",
      "For a sample size of 91\n",
      " % treated in candidate: 86.81%\n",
      "For a sample size of 70\n",
      " % treated in candidate: 80.0%\n",
      "For a sample size of 57\n",
      " % treated in candidate: 70.18%\n",
      "For a sample size of 83\n",
      " % treated in candidate: 68.67%\n",
      "For a sample size of 112\n",
      " % treated in candidate: 81.25%\n",
      "For a sample size of 72\n",
      " % treated in candidate: 91.67%\n",
      "For a sample size of 51\n",
      " % treated in candidate: 66.67%\n",
      "For a sample size of 107\n",
      " % treated in candidate: 79.44%\n",
      "For a sample size of 136\n",
      " % treated in candidate: 72.06%\n",
      "For a sample size of 81\n",
      " % treated in candidate: 0.0%\n",
      "For a sample size of 80\n",
      " % treated in candidate: 0.0%\n",
      "For a sample size of 117\n",
      " % treated in candidate: 73.5%\n",
      "For a sample size of 53\n",
      " % treated in candidate: 100.0%\n",
      "For a sample size of 61\n",
      " % treated in candidate: 54.1%\n",
      "For a sample size of 112\n",
      " % treated in candidate: 73.21%\n",
      "For a sample size of 74\n",
      " % treated in candidate: 75.68%\n",
      "For a sample size of 132\n",
      " % treated in candidate: 94.7%\n"
     ]
    }
   ],
   "source": [
    "for _,candidate in candidate_sites.items():\n",
    "    print(f\"For a sample size of {np.shape(candidate)[0]}\")\n",
    "    print(f\" % treated in candidate: {round(100 * candidate['T'].mean(),2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, candidate in candidate_sites.items():\n",
    "    X_cand = torch.from_numpy(candidate.drop(columns=[\"Y\"]).values)\n",
    "    bayes_reg = BayesianLinearRegression(prior_hyperparameters)\n",
    "    bayes_reg.set_causal_index(causal_param_first_index)\n",
    "    post_host_parameters = bayes_reg.fit(XandT_host, Y_host)\n",
    "    n_samples = n_samples_outer_expectation_obs * (n_samples_inner_expectation_obs + 1)\n",
    "\n",
    "    eig_results[\"EIG_obs_closed_form\"].append(\n",
    "            bayes_reg.closed_form_obs_EIG(X_cand)\n",
    "            )\n",
    "    eig_results[\"EIG_caus_closed_form\"].append(\n",
    "            bayes_reg.closed_form_causal_EIG(X_cand)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eig_results[\"EIG_obs_from_samples\"]=[]\n",
    "# eig_results[\"EIG_caus_from_samples\"]=[]\n",
    "\n",
    "# for i, candidate in candidate_sites.items():\n",
    "#     print(\"from samples \"+str(i))\n",
    "#     X_cand = torch.from_numpy(candidate.drop(columns=[\"Y\"]).values)\n",
    "#     bayes_reg = BayesianLinearRegression(prior_hyperparameters)\n",
    "#     bayes_reg.set_causal_index(causal_param_first_index)\n",
    "#     post_host_parameters = bayes_reg.fit(XandT_host, Y_host)\n",
    "\n",
    "#     eig_results[\"EIG_obs_from_samples\"].append(\n",
    "#             bayes_reg.samples_obs_EIG(\n",
    "#                 X_cand, n_samples_outer_expectation_obs, n_samples_inner_expectation_obs\n",
    "#             )\n",
    "#         )\n",
    "#     eig_results[\"EIG_caus_from_samples\"].append(\n",
    "#             bayes_reg.samples_causal_EIG(\n",
    "#                 X_cand, n_samples_outer_expectation_obs, n_samples_inner_expectation_obs\n",
    "#             )\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now merge and compute some CATE error\n",
    "merged_datasets = {}\n",
    "\n",
    "for i, candidate in candidate_sites.items():\n",
    "    merged_datasets[i]= pd.concat([host, candidate], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_diff = {}\n",
    "merged_mse = []\n",
    "XandT_host=host.drop(columns=[\"Y\"])\n",
    "\n",
    "X_zero = XandT_host.copy() # we predict on host with T=0 and T=1\n",
    "X_zero.iloc[:,causal_param_first_index:] = 0\n",
    "\n",
    "X_one = XandT_host.copy()\n",
    "X_one.iloc[:,causal_param_first_index:] = XandT_host.iloc[:,:causal_param_first_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging and computing ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import log_loss\n",
    "merged_mse = []\n",
    "\n",
    "for i, candidate in merged_datasets.items():\n",
    "\n",
    "    XandT_merged = candidate.drop(columns=[\"Y\"])\n",
    "    Y_merged = candidate['Y']\n",
    "\n",
    "    learner = LinearRegression(fit_intercept=False)\n",
    "    learner.fit(y=Y_merged, X=XandT_merged) # we fit on merged datasets\n",
    "\n",
    "    true_cate = data_with_groundtruth.loc[host.index, 'ite']\n",
    "\n",
    "    pred_cate = learner.predict(X_one)-learner.predict(X_zero)\n",
    "\n",
    "    merged_mse.append(mean_squared_error(true_cate, pred_cate))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing our EIGs with ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 27, 13, 42, 25, 3, 1, 16, 50, 48, 21, 41, 6, 17, 28, 8, 45, 10, 38, 34, 0, 32, 14, 31, 37, 20, 39, 15, 30, 35, 11, 29, 12, 33, 5, 49, 24, 36, 19, 46, 40, 23, 7, 22, 47, 18, 9, 26, 43, 44, 4]\n",
      "[2, 27, 13, 25, 42, 3, 1, 16, 48, 21, 6, 41, 50, 17, 28, 8, 38, 45, 10, 0, 34, 14, 32, 31, 20, 37, 39, 30, 35, 11, 29, 33, 15, 5, 49, 12, 24, 36, 19, 46, 40, 18, 47, 9, 23, 7, 22, 26, 4, 44, 43]\n",
      "[3, 27, 26, 2, 1, 22, 44, 42, 7, 28, 21, 13, 16, 48, 25, 8, 6, 9, 39, 15, 31, 17, 10, 32, 34, 41, 35, 37, 11, 38, 14, 49, 40, 19, 47, 20, 0, 18, 12, 36, 30, 33, 45, 24, 5, 50, 46, 4, 29, 23, 43]\n"
     ]
    }
   ],
   "source": [
    "obs_eig_ranking_closed_form = sorted(range(len(eig_results[\"EIG_obs_closed_form\"])), key=lambda i: eig_results[\"EIG_obs_closed_form\"][i], reverse=True)\n",
    "print(obs_eig_ranking_closed_form)\n",
    "\n",
    "caus_eig_ranking_closed_form = sorted(range(len(eig_results[\"EIG_caus_closed_form\"])), key=lambda i: eig_results[\"EIG_caus_closed_form\"][i], reverse=True)\n",
    "print(caus_eig_ranking_closed_form)\n",
    "\n",
    "# obs_eig_ranking_from_samples = sorted(range(len(eig_results[\"EIG_obs_from_samples\"])), key=lambda i: eig_results[\"EIG_obs_from_samples\"][i], reverse=True)\n",
    "# print(obs_eig_ranking_from_samples)\n",
    "\n",
    "# caus_eig_ranking_from_samples = sorted(range(len(eig_results[\"EIG_caus_from_samples\"])), key=lambda i: eig_results[\"EIG_caus_from_samples\"][i], reverse=True)\n",
    "# print(caus_eig_ranking_from_samples)\n",
    "\n",
    "true_cate_ranking = sorted(range(len(merged_mse)), key=lambda i: merged_mse[i], reverse=False) # reverse is False because its error terms\n",
    "print(true_cate_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 20\n",
    "top_n = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tau': [-0.11578947368421053, -0.2105263157894737],\n",
       " 'rho': [-0.1819548872180451, -0.3218045112781954],\n",
       " 'precision_at_k': [1.0, 1.0],\n",
       " 'recall_at_k': [0.39215686274509803, 0.39215686274509803],\n",
       " 'mean average precision': [0.8630710128245707, 0.8930264856912737],\n",
       " 'ndcg': [0.9999999999999998, 0.9999999999999998],\n",
       " 'rank corr eig': [-0.1946170824432616, -0.4077302695680013],\n",
       " 'mean reciprocal rank': [1.0, 1.0]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_with_true_rankings={'tau':[],'rho':[], \\\n",
    "      'precision_at_k': [], 'recall_at_k':[], 'mean average precision': [], \\\n",
    "      'ndcg': [], 'rank corr eig': [], 'mean reciprocal rank': []}\n",
    "\n",
    "compare_to_ground_truth(correlation_with_true_rankings, true_cate_ranking, obs_eig_ranking_closed_form, top_n = top_n, k = k)\n",
    "compare_to_ground_truth(correlation_with_true_rankings, true_cate_ranking, caus_eig_ranking_closed_form, top_n = top_n, k = k)\n",
    "\n",
    "# compare_to_ground_truth(correlation_with_true_rankings, true_cate_ranking, obs_eig_ranking_from_samples, top_n = top_n, k = k)\n",
    "# compare_to_ground_truth(correlation_with_true_rankings, true_cate_ranking, caus_eig_ranking_from_samples, top_n = top_n, k = k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50 13 40 17 34  9 19 24 27 26 15 36 12 39 47 31  7 25 14 38  5 33 20  6\n",
      " 43  4  3 45 32 48  8  1 46 41 29 49 22 23 28 37 42 44 16 18  2 11 21 30\n",
      " 10 35]\n",
      "[14, 4, 29, 44, 27, 8, 2, 52, 25, 24, 17, 3, 47, 40, 50, 23, 43, 7, 19, 9, 30, 11, 1, 36, 15, 16, 34, 33, 13, 39, 45, 22, 46, 28, 32, 6, 51, 26, 12, 41, 37, 31, 21, 35, 49, 38, 10, 20, 5, 48, 42]\n",
      "[47, 18, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50]\n",
      "[35, 19, 11, 14, 39, 47, 36, 49, 40, 5, 33, 31, 20, 24, 37, 30, 12, 10, 32, 34, 41, 18, 45, 6, 46, 8, 28, 29, 17, 50, 48, 15, 21, 38, 16, 25, 42, 2, 0, 27, 9, 1, 13, 7, 22, 23, 26, 43, 44, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "### random ranking\n",
    "random_ranking = np.random.choice(np.arange(1, number_of_candidate_sites+1), size=number_of_candidate_sites, replace=False)\n",
    "\n",
    "\n",
    "### ranking by sample size\n",
    "sample_size_order = sorted(candidate_sites.keys(), key=lambda key: -candidate_sites[key].shape[0])\n",
    "\n",
    "\n",
    "### ranking by similarity of covariate distribution\n",
    "mean_vector_host = XandT_host.iloc[:,:causal_param_first_index].mean()\n",
    "cov_matrix_host = XandT_host.iloc[:,:causal_param_first_index].cov()\n",
    "mvn = multivariate_normal(mean=mean_vector_host, cov=cov_matrix_host, allow_singular=1)\n",
    "# get log likelihood of candidate sites\n",
    "log_likelihood_list=[]\n",
    "for i, candidate in candidate_sites.items():\n",
    "    log_likelihoods=mvn.logpdf(candidate.iloc[:,:causal_param_first_index].values)\n",
    "    log_likelihood_list.append(np.mean(log_likelihoods))\n",
    "\n",
    "similarity_cov_distrib_ranking= sorted(range(len(log_likelihood_list)), key=lambda i: log_likelihood_list[i], reverse=True)\n",
    "\n",
    "### ranking by similarity of propensity scores\n",
    "# we fit a propensity score model at target site and store logloss\n",
    "# for each site: we fit the model further on the cand site and compute log\n",
    "# nd assess the loss. Sites associated with loss values with higher discrepancy from the host should have distinct \n",
    "#treatment allocation scheme, and thus be a better fit. \n",
    "\n",
    "ps_model = LinearRegression(fit_intercept=False)\n",
    "ps_model.fit(XandT_host.iloc[:,:causal_param_first_index], XandT_host['T'])\n",
    "t_host_pred = ps_model.predict(XandT_host.iloc[:,:causal_param_first_index])\n",
    "mse_host = mean_squared_error(t_host_pred, XandT_host['T'])\n",
    "mse_diff_list = []\n",
    "\n",
    "for i, candidate in candidate_sites.items():\n",
    "    ps_model_copy= copy.deepcopy(ps_model)\n",
    "    ps_model_copy.fit(candidate.iloc[:,:causal_param_first_index], candidate['T'])\n",
    "    t_cand_pred = ps_model_copy.predict(XandT_host.iloc[:,:causal_param_first_index]) # predict on host!\n",
    "    mse_cand = abs(mean_squared_error(t_cand_pred, XandT_host['T']) - mse_host)\n",
    "    mse_diff_list.append(mse_cand)\n",
    "\n",
    "similarity_pscore_ranking = sorted(range(len(mse_diff_list)), key=lambda i: mse_diff_list[i], reverse=True) \n",
    "# the more diff in pscore the better so reverse=True\n",
    "\n",
    "\n",
    "print(random_ranking)\n",
    "print(sample_size_order)\n",
    "print(similarity_cov_distrib_ranking)\n",
    "print(similarity_pscore_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tau': [-0.11578947368421053,\n",
       "  -0.2105263157894737,\n",
       "  -0.031578947368421054,\n",
       "  -0.052631578947368425,\n",
       "  -0.052631578947368425,\n",
       "  0.010526315789473684],\n",
       " 'rho': [-0.1819548872180451,\n",
       "  -0.3218045112781954,\n",
       "  -0.0706766917293233,\n",
       "  -0.04661654135338346,\n",
       "  -0.030075187969924807,\n",
       "  0.019548872180451125],\n",
       " 'precision_at_k': [1.0, 1.0, 1.0, 0.95, 1.0, 1.0],\n",
       " 'recall_at_k': [0.39215686274509803,\n",
       "  0.39215686274509803,\n",
       "  0.39215686274509803,\n",
       "  0.37254901960784315,\n",
       "  0.39215686274509803,\n",
       "  0.39215686274509803],\n",
       " 'mean average precision': [0.8630710128245707,\n",
       "  0.8930264856912737,\n",
       "  0.14902158436505905,\n",
       "  0.1609595249595019,\n",
       "  0.17271240697347895,\n",
       "  0.015144063238103486],\n",
       " 'ndcg': [0.9999999999999998,\n",
       "  0.9999999999999998,\n",
       "  0.9999999999999998,\n",
       "  0.9999999999999998,\n",
       "  0.9999999999999998,\n",
       "  0.9999999999999998],\n",
       " 'rank corr eig': [-0.1946170824432616,\n",
       "  -0.4077302695680013,\n",
       "  -0.08152995480447862,\n",
       "  0.04820902594204496,\n",
       "  -0.2081776770736918,\n",
       "  0.14167823496897794],\n",
       " 'mean reciprocal rank': [1.0, 1.0, 0.5, 0.25, 0.25, 0.2]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_to_ground_truth(correlation_with_true_rankings, true_cate_ranking, random_ranking, top_n = top_n, k = k)\n",
    "compare_to_ground_truth(correlation_with_true_rankings, true_cate_ranking, sample_size_order, top_n = top_n, k = k)\n",
    "compare_to_ground_truth(correlation_with_true_rankings, true_cate_ranking, similarity_cov_distrib_ranking, top_n = top_n, k = k)\n",
    "compare_to_ground_truth(correlation_with_true_rankings, true_cate_ranking, similarity_pscore_ranking, top_n = top_n, k = k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau</th>\n",
       "      <th>rho</th>\n",
       "      <th>precision_at_k</th>\n",
       "      <th>recall_at_k</th>\n",
       "      <th>mean average precision</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>rank corr eig</th>\n",
       "      <th>mean reciprocal rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>obs_closed_form</th>\n",
       "      <td>-0.115789</td>\n",
       "      <td>-0.181955</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.863071</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.194617</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caus_closed_form</th>\n",
       "      <td>-0.210526</td>\n",
       "      <td>-0.321805</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.893026</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.407730</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>-0.031579</td>\n",
       "      <td>-0.070677</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.149022</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.081530</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample size</th>\n",
       "      <td>-0.052632</td>\n",
       "      <td>-0.046617</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.160960</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.048209</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similarity_cov_distrib_ranking</th>\n",
       "      <td>-0.052632</td>\n",
       "      <td>-0.030075</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.172712</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.208178</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similarity_pscore_ranking size</th>\n",
       "      <td>0.010526</td>\n",
       "      <td>0.019549</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.015144</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.141678</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     tau       rho  precision_at_k  \\\n",
       "obs_closed_form                -0.115789 -0.181955            1.00   \n",
       "caus_closed_form               -0.210526 -0.321805            1.00   \n",
       "random                         -0.031579 -0.070677            1.00   \n",
       "sample size                    -0.052632 -0.046617            0.95   \n",
       "similarity_cov_distrib_ranking -0.052632 -0.030075            1.00   \n",
       "similarity_pscore_ranking size  0.010526  0.019549            1.00   \n",
       "\n",
       "                                recall_at_k  mean average precision  ndcg  \\\n",
       "obs_closed_form                    0.392157                0.863071   1.0   \n",
       "caus_closed_form                   0.392157                0.893026   1.0   \n",
       "random                             0.392157                0.149022   1.0   \n",
       "sample size                        0.372549                0.160960   1.0   \n",
       "similarity_cov_distrib_ranking     0.392157                0.172712   1.0   \n",
       "similarity_pscore_ranking size     0.392157                0.015144   1.0   \n",
       "\n",
       "                                rank corr eig  mean reciprocal rank  \n",
       "obs_closed_form                     -0.194617                  1.00  \n",
       "caus_closed_form                    -0.407730                  1.00  \n",
       "random                              -0.081530                  0.50  \n",
       "sample size                          0.048209                  0.25  \n",
       "similarity_cov_distrib_ranking      -0.208178                  0.25  \n",
       "similarity_pscore_ranking size       0.141678                  0.20  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_with_true_rankings= pd.DataFrame.from_dict(correlation_with_true_rankings)\n",
    "correlation_with_true_rankings.index = ['obs_closed_form', 'caus_closed_form', 'random', 'sample size', 'similarity_cov_distrib_ranking', 'similarity_pscore_ranking size'] #, 'obs_from_samples', 'caus_from_samples']\n",
    "correlation_with_true_rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### below is version where ground truth is wrt merged dataset\n",
    "\n",
    "# for i, candidate in merged_datasets.items():\n",
    "\n",
    "#     XandT_merged = candidate.drop(columns=[\"Y\"])\n",
    "#     Y_merged = candidate['Y']\n",
    "\n",
    "#     learner = LinearRegression(fit_intercept=False)\n",
    "#     learner.fit(y=Y_merged, X=XandT_merged) # we fit on merged datasets\n",
    "\n",
    "#     true_cate = data_with_groundtruth.loc[XandT_merged.index, 'ite']\n",
    "\n",
    "#     X_zero = XandT_merged.copy() # we predict on host with T=0 and T=1\n",
    "#     X_zero.iloc[:,causal_param_first_index:] = 0\n",
    "\n",
    "#     X_one = XandT_merged.copy()\n",
    "#     X_one.iloc[:,causal_param_first_index:] = XandT_merged.iloc[:,:causal_param_first_index]\n",
    "\n",
    "#     pred_cate = learner.predict(X_one)-learner.predict(X_zero)\n",
    "\n",
    "#     merged_mse.append(mean_squared_error(true_cate, pred_cate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bart stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_host, T_host, Y_host = host.drop(columns=['T','Y']).values, host['T'].values.astype(np.int32), host['Y'].values\n",
    "\n",
    "# prior_hyperparameters = {'sigma_0_sq':1, 'p_categorical_pr':0, 'p_categorical_trt':0 }\n",
    "# predictive_model_parameters={\"num_trees_pr\":200,\"num_trees_trt\":100}\n",
    "# conditional_model_param={\"num_trees_pr\":200}\n",
    "\n",
    "\n",
    "# for i, candidate in candidate_sites.items():\n",
    "\n",
    "#     print(\"from samples \"+str(i))\n",
    "#     X_cand, T_cand = candidate.drop(columns=['Y','T']).values, candidate['T'].values.astype(np.int32)\n",
    "\n",
    "#     bcf = BayesianCausalForest(\n",
    "#         prior_hyperparameters,\n",
    "#         predictive_model_parameters=predictive_model_parameters,\n",
    "#         conditional_model_param=conditional_model_param)\n",
    "#     bcf.store_train_data(X=X_host, T=T_host, Y=Y_host)\n",
    "    \n",
    "#     joint_eig = bcf.joint_EIG_calc(X_cand, T_cand, sampling_parameters)\n",
    "\n",
    "#     results[\"EIG_obs_bart\"].append(joint_eig[\"Obs EIG\"])\n",
    "#     results[\"EIG_caus_bart\"].append(joint_eig[\"Causal EIG\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pjake_kernel",
   "language": "python",
   "name": "pjake_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
