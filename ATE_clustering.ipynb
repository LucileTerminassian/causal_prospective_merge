{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03898823-96ff-428f-b4f1-6083410880ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MERGE_EVALUATION METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c45d11b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_BaseMixture' from 'sklearn.mixture' (/usr/local/lib/python3.9/site-packages/sklearn/mixture/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/95/2fxvyl4560l2_2s1dty0_zcr0000gn/T/ipykernel_65636/1396450903.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# from sklearn.mixture import DirichletProcess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# from sklearn.mixture import CategoricalMixture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixture\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_BaseMixture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_BaseMixture' from 'sklearn.mixture' (/usr/local/lib/python3.9/site-packages/sklearn/mixture/__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from hmmlearn import hmm\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.mixture import DirichletProcess\n",
    "from sklearn.mixture import CategoricalMixture\n",
    "from sklearn.mixture import _BaseMixture\n",
    "import numpy as np\n",
    "\n",
    "class ATE_clustering:\n",
    "    def __init__(self, algorithm='GMM', likelihood_threshold=0.5, null_cluster_label=-1, random_state=None):\n",
    "        self.algorithm = algorithm\n",
    "        self.likelihood_threshold = likelihood_threshold\n",
    "        self.null_cluster_label = null_cluster_label\n",
    "        self.model = None\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, x, t):\n",
    "        # Check if input is a DataFrame or an array and convert to DataFrame\n",
    "        if not isinstance(x, pd.DataFrame):\n",
    "            x = pd.DataFrame(x)\n",
    "\n",
    "        if not isinstance(t, pd.Series):\n",
    "            t = pd.Series(t, name='treatment')\n",
    "\n",
    "        # Initialize the clustering algorithm\n",
    "        if self.algorithm == 'GMM':\n",
    "            self.model = GaussianMixture(random_state=self.random_state)\n",
    "        elif self.algorithm == 'HMM':\n",
    "            self.model = hmm.GaussianHMM(random_state=self.random_state)\n",
    "        elif self.algorithm == 'MoE':\n",
    "            # Mixture of Experts is not directly available in scikit-learn, you may need a custom implementation\n",
    "            # Here, we use BayesianGaussianMixture as a placeholder\n",
    "            self.model = BayesianGaussianMixture(random_state=self.random_state)\n",
    "        elif self.algorithm == 'LDA':\n",
    "            self.model = _BaseMixture(component=CategoricalMixture, random_state=self.random_state)\n",
    "        elif self.algorithm == 'DPMM':\n",
    "            self.model = DirichletProcess(random_state=self.random_state)\n",
    "        elif self.algorithm == 'BGMM':\n",
    "            self.model = BayesianGaussianMixture(random_state=self.random_state)\n",
    "        elif self.algorithm == 'FMM':\n",
    "            self.model = _BaseMixture(component=CategoricalMixture, random_state=self.random_state)\n",
    "        elif self.algorithm == 'EM':\n",
    "            # EM clustering is not directly available in scikit-learn, you may need a custom implementation\n",
    "            # Here, we use GaussianMixture as a placeholder\n",
    "            self.model = GaussianMixture(random_state=self.random_state)\n",
    "        elif self.algorithm == 'CMM':\n",
    "            self.model = CategoricalMixture(random_state=self.random_state)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported clustering algorithm. Supported algorithms: 'GMM', 'HMM', 'MoE', 'LDA', 'DPMM', 'BGMM', 'FMM', 'EM', 'CMM'.\")\n",
    "\n",
    "        # Fit the model with x\n",
    "        self.model.fit(x)\n",
    "\n",
    "    def evaluate_private(self, x, t):\n",
    "        # Check if input is a DataFrame or an array and convert to DataFrame\n",
    "        if not isinstance(x, pd.DataFrame):\n",
    "            x = pd.DataFrame(x)\n",
    "\n",
    "        if not isinstance(t, pd.Series):\n",
    "            t = pd.Series(t, name='treatment')\n",
    "\n",
    "        # Get the likelihood scores for each sample\n",
    "        likelihoods = self.model.score_samples(x)\n",
    "\n",
    "        # Assign samples with low likelihoods to the null cluster\n",
    "        clusters = [self.null_cluster_label if likelihood < self.likelihood_threshold else cluster\n",
    "                    for cluster, likelihood in zip(self.model.predict(x), likelihoods)]\n",
    "\n",
    "        # Create a DataFrame with cluster indices, treated sample size, and untreated sample size\n",
    "        evaluation_df = pd.DataFrame({'Cluster_Index': clusters,\n",
    "                                      'Treated_Size': t.groupby(clusters).sum(),\n",
    "                                      'Untreated_Size': (1 - t).groupby(clusters).sum(),\n",
    "                                      'Treated_Var_Y': 0.0,\n",
    "                                      'Untreated_Var_Y': 0.0})\n",
    "\n",
    "        # Compute variances for each cluster\n",
    "        for cluster_index, cluster_data in evaluation_df.groupby('Cluster_Index'):\n",
    "            treated_y_var = y[t & (evaluation_df['Cluster_Index'] == cluster_index)].var()\n",
    "            untreated_y_var = y[~t & (evaluation_df['Cluster_Index'] == cluster_index)].var()\n",
    "\n",
    "            evaluation_df.loc[evaluation_df['Cluster_Index'] == cluster_index, 'Treated_Var_Y'] = treated_y_var\n",
    "            evaluation_df.loc[evaluation_df['Cluster_Index'] == cluster_index, 'Untreated_Var_Y'] = untreated_y_var\n",
    "\n",
    "        # Add a column for the proportion of samples in each cluster\n",
    "        evaluation_df['Probability_Cluster'] = evaluation_df.groupby('Cluster_Index')['Cluster_Index'].transform('count') / len(x)\n",
    "\n",
    "        return evaluation_df\n",
    "\n",
    "    def compute_info_gain(self, evaluation_df_host, evaluation_df_candidate):\n",
    "        \"\"\"\n",
    "        Compute Information Gain between host and candidate datasets.\n",
    "\n",
    "        Parameters:\n",
    "        - evaluation_df_host (DataFrame): Complete non-private summary for the host dataset.\n",
    "        - evaluation_df_candidate (DataFrame): Partial summary for the candidate dataset.\n",
    "\n",
    "        Returns:\n",
    "        - float: Information Gain ratio.\n",
    "        \"\"\"\n",
    "        # Check if input is a DataFrame or an array and convert to DataFrame\n",
    "        if not isinstance(evaluation_df_host, pd.DataFrame):\n",
    "            evaluation_df_host = pd.DataFrame(evaluation_df_host)\n",
    "\n",
    "        if not isinstance(evaluation_df_candidate, pd.DataFrame):\n",
    "            evaluation_df_candidate = pd.DataFrame(evaluation_df_candidate)\n",
    "\n",
    "        # Compute var_host_estimator\n",
    "        pi_host = evaluation_df_host['Probability_Cluster']\n",
    "        sigma_treated_host = evaluation_df_host['Treated_Var_Y']\n",
    "        sigma_untreated_host = evaluation_df_host['Untreated_Var_Y']\n",
    "        n_treated_host = evaluation_df_host['Treated_Size']\n",
    "        n_untreated_host = evaluation_df_host['Untreated_Size']\n",
    "\n",
    "        var_host_estimator = np.sum((pi_host ** 2 / 2) * ((sigma_treated_host / n_treated_host) + (sigma_untreated_host / n_untreated_host)))\n",
    "\n",
    "        # Compute var_merged_estimator\n",
    "        n_treated_candidate = evaluation_df_candidate['Treated_Size_Host']\n",
    "        n_untreated_candidate = evaluation_df_candidate['Untreated_Size_Host']\n",
    "\n",
    "        var_merged_estimator = np.sum((pi_host ** 2 / 2) * ((sigma_treated_host / (n_treated_host + n_treated_candidate)) + (sigma_untreated_host / (n_untreated_host + n_untreated_candidate))))\n",
    "\n",
    "        # Compute Information Gain ratio\n",
    "        info_gain_ratio = var_merged_estimator / var_host_estimator\n",
    "\n",
    "        return info_gain_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1d216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# Instantiate the ATE_clustering class with different algorithms and a likelihood threshold\n",
    "ate_gmm = ATE_clustering(algorithm='GMM', likelihood_threshold=0.5)\n",
    "ate_hmm = ATE_clustering(algorithm='HMM', likelihood_threshold=0.5)\n",
    "ate_moe = ATE_clustering(algorithm='MoE', likelihood_threshold=0.5)\n",
    "ate_lda = ATE_clustering(algorithm='LDA', likelihood_threshold=0.5)\n",
    "ate_dpmm = ATE_clustering(algorithm='DPMM', likelihood_threshold=0.5)\n",
    "ate_bgmm = ATE_clustering(algorithm='BGMM', likelihood_threshold=0.5)\n",
    "ate_fmm = ATE_clustering(algorithm='FMM', likelihood_threshold=0.5)\n",
    "ate_em = ATE_clustering(algorithm='EM', likelihood_threshold=0.5)\n",
    "ate_cmm = ATE_clustering(algorithm='CMM', likelihood_threshold=0.5)\n",
    "\n",
    "# Example data\n",
    "example_x_host = pd.DataFrame({\n",
    "    'Feature1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'Feature2': [11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "})\n",
    "\n",
    "example_t_host = pd.Series([0, 1, 0, 1, 0, 1, 0, 1, 0, 1], name='Treatment')\n",
    "example_y_host = pd.Series([25, 30, 35, 40, 45, 50, 55, 60, 65, 70], name='Outcome')\n",
    "\n",
    "example_x_candidate = pd.DataFrame({\n",
    "    'Feature1': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
    "    'Feature2': [12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
    "})\n",
    "\n",
    "example_t_candidate = pd.Series([1, 0, 1, 0, 1, 0, 1, 0, 1, 0], name='Treatment')\n",
    "example_y_candidate = pd.Series([32, 36, 41, 38, 48, 52, 55, 60, 68, 70], name='Outcome')\n",
    "\n",
    "# Fit and evaluate using different algorithms\n",
    "ate_gmm.fit(example_x_host, example_t_host)\n",
    "evaluation_gmm_host = ate_gmm.compute_summary_stats_non_private(example_x_host, example_t_host, example_y_host)\n",
    "evaluation_gmm_candidate = ate_gmm.evaluate_private(example_x_candidate, example_t_candidate)\n",
    "info_gain_gmm = ate_gmm.compute_info_gain(evaluation_gmm_host, evaluation_gmm_candidate)\n",
    "print(\"Information Gain (GMM):\", info_gain_gmm)\n",
    "\n",
    "# Repeat the above steps for other algorithms as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df47bc88-ad3f-41ec-9a8a-9f4182949f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clustering class \n",
    "\n",
    "# parameters: 'clustering algorithm' \n",
    "# inputs: x, t\n",
    "\n",
    "# fit function : fits the clustering algorithm and returns the fitted model\n",
    "\n",
    "# evaluate_private function : \n",
    "# takes in as an input (x,t) \n",
    "# returns a vector of cluster index and treated/untreated sample size\n",
    "\n",
    "# for later\n",
    "# describe function: \n",
    "# input would be the fitted model\n",
    "# returns a description each cluster in terms of covariate partition, with corresponding cluster index\n",
    "\n",
    "\n",
    "\n",
    "## Computation class\n",
    "\n",
    "# we just take the variance of the outcome in each cluster for treated and untreatd, looking only at our dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147556a7-09a4-40f7-a55b-f1a74b8a88a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa04ce9e-ac13-4874-abff-cf164cb4f363",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data class \n",
    "\n",
    "# each object has a dataframe attribute\n",
    "# some way to declare datasets and merge them easily\n",
    "# function to merge datasets (could use add)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1032ee50-5cff-43c5-84ee-3fa53f4862ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simulated examples\n",
    "\n",
    "# 1 class = 1 experiment\n",
    "# returns a set of datasets (doesn't have to be 2)\n",
    "\n",
    "# experiment 1\n",
    "# input parameters: (sigma, sample size, eps)\n",
    "# the ideal match or some noisy version of that (have the noise as a parameter)\n",
    "\n",
    "# this setting = in the regions where we have a lot of data is where overlap will be good \n",
    "# reinforcing the regions of good overlap\n",
    "# we would like to have \n",
    "\n",
    "# dataset A: pi_A(x) = sigmoid(x) \n",
    "# X_A : 1 dimensional normal covariate with mean 0 \n",
    "\n",
    "# dataset B: pi_B(x) = sigmoid(-x) \n",
    "# X_B : 1 dimensional normal covariate with mean eps\n",
    "# eps being 0 would be the ideal match \n",
    "# eps the further away from 0 we will have more samples in a region where there used to high uncertainty\n",
    "\n",
    "# experiment 2\n",
    "# input parameters: (sigma, sample size, eps)\n",
    "# same thing but play with sigma instead of eps\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
