{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucile/causal_info_gain/pjake/lib/python3.9/site-packages/torch/__init__.py:696: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:453.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "torch.set_default_tensor_type(torch.FloatTensor) \n",
    "import copy\n",
    "import sys\n",
    "import os\n",
    "notebook_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(notebook_dir)\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from rct_data_generator import *\n",
    "from outcome_models import *\n",
    "from plotting_functions import *\n",
    "from mcmc_bayes_update import *\n",
    "from eig_comp_utils import *\n",
    "from research_exp_utils import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x1        x2        x3        x4        x5        x6  x7  x8  x9  \\\n",
      "0 -0.528957 -0.343685  1.129310  0.161811 -0.316815  1.295216   1   0   1   \n",
      "1 -1.738109 -1.803210  0.384085  2.245823 -0.629611  1.295216   0   0   0   \n",
      "2 -0.807992 -0.203082 -0.361140 -0.880195  0.809248 -0.526556   0   0   0   \n",
      "3  0.390344  0.596982 -1.851590 -0.880195 -0.004020 -0.857787   0   0   0   \n",
      "4 -1.045929 -0.603114  0.011473  0.161811  0.684130 -0.360940   1   0   0   \n",
      "\n",
      "   x10  ...  x17  x18  x19  x20  x21  x22  x23  x24  x25    T  \n",
      "0    0  ...    1    1    1    0    0    0    0    0    0  1.0  \n",
      "1    1  ...    1    1    1    0    0    0    0    0    0  0.0  \n",
      "2    1  ...    0    1    1    0    0    0    0    0    0  0.0  \n",
      "3    0  ...    0    1    1    0    0    0    0    0    0  0.0  \n",
      "4    0  ...    1    1    1    0    0    0    0    0    0  0.0  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "data, x, t, y = get_data(path='./', dataset='IDHP')\n",
    "XandT = pd.concat([x,t], axis=1)\n",
    "print(XandT.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_candidate_sites = 100\n",
    "\n",
    "min_sample_size_cand = 150\n",
    "max_sample_size_cand = 300\n",
    "host_sample_size = 400 \n",
    "desired_initial_sample_size = 10**4\n",
    "XandT = XandT.sample(n=desired_initial_sample_size, replace=True, random_state=42)\n",
    "added_T_coef = 50 # to increase importance of T\n",
    "\n",
    "outcome_function = None\n",
    "std_true_y = 1\n",
    "power_x = 1\n",
    "power_x_t = 1\n",
    "sigma_rand_error = 1\n",
    "true_beta_great_0_prop = 0.8\n",
    "host_test_size = 2000\n",
    "\n",
    "exp_parameters = {'number_of_candidate_sites': number_of_candidate_sites+1, 'min_sample_size_cand': min_sample_size_cand, \\\n",
    "                'max_sample_size_cand': max_sample_size_cand, 'host_sample_size': host_sample_size, 'host_test_size': host_test_size, 'outcome_function': outcome_function, \\\n",
    "                'std_true_y': std_true_y, 'power_x': power_x, 'power_x_t': power_x_t}\n",
    "\n",
    "causal_param_first_index = power_x*np.shape(XandT)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /Users/lucile/causal_info_gain/causal_prospective_merge/rct_data_generator.py:264: RuntimeWarning:overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "candidate_sites=generating_random_sites_from(XandT, data, exp_parameters, added_T_coef=1, binary_outcome=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, cand in candidate_sites.items():\n",
    "    if np.sum(cand['T'].values)<30: \n",
    "        print('less treated')\n",
    "    if len(cand['T'].values)-np.sum(cand['T'].values)<30:\n",
    "        print('less untreated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /Users/lucile/causal_info_gain/causal_prospective_merge/rct_data_generator.py:144: RuntimeWarning:overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "#dictionnary of random sites\n",
    "candidate_sites = generating_random_sites_from(XandT, exp_parameters, added_T_coef=50)\n",
    "\n",
    "for i, cand in candidate_sites.items():\n",
    "    candidate_sites[i] = pd.concat([cand, data_with_groundtruth.loc[cand.index, 'Y']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = (np.random.randn(152) > true_beta_great_0_prop)\n",
    "beta = beta - np.mean(beta)\n",
    "\n",
    "for i, cand in candidate_sites.items():\n",
    "    candidate_sites[i][\"Y\"] = candidate_sites[i].drop(columns=[\"Y\"]) @ beta \n",
    "    candidate_sites[i][\"Y\"] += 1 * np.random.randn(len(candidate_sites[i][\"Y\"]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = candidate_sites[0]\n",
    "candidate_sites = {key: value for key, value in candidate_sites.items() if key != 0}\n",
    "XandT_host, Y_host = torch.from_numpy(host.drop(columns=[\"Y\"]).values), torch.from_numpy(host[\"Y\"].values)\n",
    "\n",
    "# Prior parameters for Bayesian update on host\n",
    "d = np.shape(host)[1]-1\n",
    "prior_mean = torch.zeros(d)\n",
    "sigma_prior = 1\n",
    "beta_0, sigma_0_sq, inv_cov_0 = prior_mean, sigma_rand_error,torch.eye(d)\n",
    "prior_hyperparameters = {'beta_0': beta_0, 'sigma_0_sq': sigma_0_sq,\"inv_cov_0\":inv_cov_0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_outer_expectation_obs = 400\n",
    "n_samples_inner_expectation_obs = 800\n",
    "n_samples_outer_expectation_caus = 400\n",
    "n_samples_inner_expectation_caus = 800\n",
    "\n",
    "sampling_parameters = {'n_samples_inner_expectation_obs':n_samples_inner_expectation_obs, 'n_samples_outer_expectation_obs':n_samples_outer_expectation_obs, \\\n",
    "                       'n_samples_inner_expectation_caus':n_samples_inner_expectation_caus, 'n_samples_outer_expectation_caus':n_samples_outer_expectation_caus}\n",
    "\n",
    "eig_results = {\"EIG_obs_from_samples\": [], 'EIG_caus_from_samples':[], \"EIG_obs_closed_form\":[], \"EIG_caus_closed_form\":[], \"EIG_obs_bart\":[], \"EIG_caus_bart\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " % treated in host: 48.25%\n"
     ]
    }
   ],
   "source": [
    "print(f\" % treated in host: {round(100 * host['T'].mean(),2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a sample size of 166\n",
      " % treated in candidate: 46.99%\n",
      "For a sample size of 253\n",
      " % treated in candidate: 81.82%\n",
      "For a sample size of 226\n",
      " % treated in candidate: 83.19%\n",
      "For a sample size of 172\n",
      " % treated in candidate: 62.79%\n",
      "For a sample size of 284\n",
      " % treated in candidate: 78.17%\n",
      "For a sample size of 159\n",
      " % treated in candidate: 86.16%\n",
      "For a sample size of 263\n",
      " % treated in candidate: 13.69%\n",
      "For a sample size of 232\n",
      " % treated in candidate: 78.02%\n",
      "For a sample size of 205\n",
      " % treated in candidate: 56.1%\n",
      "For a sample size of 165\n",
      " % treated in candidate: 41.82%\n"
     ]
    }
   ],
   "source": [
    "for _,candidate in candidate_sites.items():\n",
    "    print(f\"For a sample size of {np.shape(candidate)[0]}\")\n",
    "    print(f\" % treated in candidate: {round(100 * candidate['T'].mean(),2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, candidate in candidate_sites.items():\n",
    "    X_cand = torch.from_numpy(candidate.drop(columns=[\"Y\"]).values)\n",
    "    bayes_reg = BayesianLinearRegression(prior_hyperparameters)\n",
    "    bayes_reg.set_causal_index(causal_param_first_index)\n",
    "    post_host_parameters = bayes_reg.fit(XandT_host, Y_host)\n",
    "    n_samples = n_samples_outer_expectation_obs * (n_samples_inner_expectation_obs + 1)\n",
    "\n",
    "    eig_results[\"EIG_obs_closed_form\"].append(\n",
    "            bayes_reg.closed_form_obs_EIG(X_cand)\n",
    "            )\n",
    "    eig_results[\"EIG_caus_closed_form\"].append(\n",
    "            bayes_reg.closed_form_causal_EIG(X_cand)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eig_results[\"EIG_obs_from_samples\"]=[]\n",
    "# eig_results[\"EIG_caus_from_samples\"]=[]\n",
    "\n",
    "# for i, candidate in candidate_sites.items():\n",
    "#     print(\"from samples \"+str(i))\n",
    "#     X_cand = torch.from_numpy(candidate.drop(columns=[\"Y\"]).values)\n",
    "#     bayes_reg = BayesianLinearRegression(prior_hyperparameters)\n",
    "#     bayes_reg.set_causal_index(causal_param_first_index)\n",
    "#     post_host_parameters = bayes_reg.fit(XandT_host, Y_host)\n",
    "\n",
    "#     eig_results[\"EIG_obs_from_samples\"].append(\n",
    "#             bayes_reg.samples_obs_EIG(\n",
    "#                 X_cand, n_samples_outer_expectation_obs, n_samples_inner_expectation_obs\n",
    "#             )\n",
    "#         )\n",
    "#     eig_results[\"EIG_caus_from_samples\"].append(\n",
    "#             bayes_reg.samples_causal_EIG(\n",
    "#                 X_cand, n_samples_outer_expectation_obs, n_samples_inner_expectation_obs\n",
    "#             )\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now merge and compute some CATE error\n",
    "merged_datasets = {}\n",
    "\n",
    "for i, candidate in candidate_sites.items():\n",
    "    merged_datasets[i]= pd.concat([host, candidate], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_diff = {}\n",
    "merged_mse = []\n",
    "XandT_host=host.drop(columns=[\"Y\"])\n",
    "\n",
    "X_zero = XandT_host.copy() # we predict on host with T=0 and T=1\n",
    "X_zero.iloc[:,causal_param_first_index:] = 0\n",
    "\n",
    "X_one = XandT_host.copy()\n",
    "X_one.iloc[:,causal_param_first_index:] = XandT_host.iloc[:,:causal_param_first_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging and computing ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "merged_mse = []\n",
    "\n",
    "for i, candidate in merged_datasets.items():\n",
    "\n",
    "    XandT_merged = candidate.drop(columns=[\"Y\"])\n",
    "    Y_merged = candidate['Y']\n",
    "\n",
    "    learner = Ridge(fit_intercept=True)\n",
    "    learner.fit(y=Y_merged, X=XandT_merged) # we fit on merged datasets\n",
    "\n",
    "    true_cate = (X_one - X_zero) @ beta\n",
    "\n",
    "    pred_cate = learner.predict(X_one)-learner.predict(X_zero)\n",
    "\n",
    "    merged_mse.append(mean_squared_error(true_cate, pred_cate))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing our EIGs with ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 4, 7, 1, 8, 2, 0, 3, 9, 5]\n",
      "[7, 4, 8, 6, 1, 2, 3, 0, 9, 5]\n",
      "[2, 7, 9, 4, 8, 1, 3, 0, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "obs_eig_ranking_closed_form = sorted(range(len(eig_results[\"EIG_obs_closed_form\"])), key=lambda i: eig_results[\"EIG_obs_closed_form\"][i], reverse=True)\n",
    "print(obs_eig_ranking_closed_form)\n",
    "\n",
    "caus_eig_ranking_closed_form = sorted(range(len(eig_results[\"EIG_caus_closed_form\"])), key=lambda i: eig_results[\"EIG_caus_closed_form\"][i], reverse=True)\n",
    "print(caus_eig_ranking_closed_form)\n",
    "\n",
    "# obs_eig_ranking_from_samples = sorted(range(len(eig_results[\"EIG_obs_from_samples\"])), key=lambda i: eig_results[\"EIG_obs_from_samples\"][i], reverse=True)\n",
    "# print(obs_eig_ranking_from_samples)\n",
    "\n",
    "# caus_eig_ranking_from_samples = sorted(range(len(eig_results[\"EIG_caus_from_samples\"])), key=lambda i: eig_results[\"EIG_caus_from_samples\"][i], reverse=True)\n",
    "# print(caus_eig_ranking_from_samples)\n",
    "\n",
    "true_cate_ranking = sorted(range(len(merged_mse)), key=lambda i: merged_mse[i], reverse=False) # reverse is False because its error terms\n",
    "print(true_cate_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "k =[1,3,5]\n",
    "top_n = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision_at_1': [0.0, 0.0],\n",
       " 'precision_at_3': [0.3333333333333333, 0.3333333333333333],\n",
       " 'precision_at_5': [0.6, 0.6],\n",
       " 'tau': [0.06666666666666667, 0.3333333333333333],\n",
       " 'rho': [0.06666666666666665, 0.34545454545454546]}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_with_true_rankings={}\n",
    "\n",
    "for val in k:\n",
    "    correlation_with_true_rankings['precision_at_'+str(val)] = []\n",
    "compare_to_ground_truth(correlation_with_true_rankings, true_cate_ranking, obs_eig_ranking_closed_form, merged_mse=merged_mse, top_n = top_n, k = k)\n",
    "compare_to_ground_truth(correlation_with_true_rankings, true_cate_ranking, caus_eig_ranking_closed_form,merged_mse=merged_mse, top_n = top_n, k = k)\n",
    "\n",
    "# compare_to_ground_truth(correlation_with_true_rankings, true_cate_ranking, obs_eig_ranking_from_samples, top_n = top_n, k = k)\n",
    "# compare_to_ground_truth(correlation_with_true_rankings, true_cate_ranking, caus_eig_ranking_from_samples, top_n = top_n, k = k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  7  1  5  2  4  8  3  9  6]\n",
      "[5, 7, 2, 8, 3, 9, 4, 1, 10, 6]\n",
      "[2, 0, 1, 3, 4, 5, 6, 7, 8, 9]\n",
      "[5, 2, 4, 7, 1, 3, 8, 0, 9, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /Users/lucile/causal_info_gain/pjake/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning:lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "### random ranking\n",
    "random_ranking = np.random.choice(np.arange(1, number_of_candidate_sites+1), size=number_of_candidate_sites, replace=False)\n",
    "\n",
    "\n",
    "### ranking by sample size\n",
    "sample_size_order = sorted(candidate_sites.keys(), key=lambda key: -candidate_sites[key].shape[0])\n",
    "\n",
    "\n",
    "### ranking by similarity of covariate distribution\n",
    "mean_vector_host = XandT_host.iloc[:,:causal_param_first_index].mean()\n",
    "cov_matrix_host = XandT_host.iloc[:,:causal_param_first_index].cov()\n",
    "mvn = multivariate_normal(mean=mean_vector_host, cov=cov_matrix_host, allow_singular=1)\n",
    "# get log likelihood of candidate sites\n",
    "log_likelihood_list=[]\n",
    "for i, candidate in candidate_sites.items():\n",
    "    log_likelihoods=mvn.logpdf(candidate.iloc[:,:causal_param_first_index].values)\n",
    "    log_likelihood_list.append(np.mean(log_likelihoods))\n",
    "\n",
    "similarity_cov_distrib_ranking= sorted(range(len(log_likelihood_list)), key=lambda i: log_likelihood_list[i], reverse=True)\n",
    "\n",
    "### ranking by similarity of propensity scores\n",
    "# we fit a propensity score model at target site and store logloss\n",
    "# for each site: we fit the model further on the cand site and compute log\n",
    "# nd assess the loss. Sites associated with loss values with higher discrepancy from the host should have distinct \n",
    "#treatment allocation scheme, and thus be a better fit. \n",
    "\n",
    "ps_model = LogisticRegression(fit_intercept=True)\n",
    "ps_model.fit(XandT_host.iloc[:,:causal_param_first_index], XandT_host['T'])\n",
    "t_host_pred = ps_model.predict(XandT_host.iloc[:,:causal_param_first_index])\n",
    "mse_host = mean_squared_error(t_host_pred, XandT_host['T'])\n",
    "mse_diff_list = []\n",
    "\n",
    "\n",
    "for i, candidate in candidate_sites.items():\n",
    "    # ps_model_copy= copy.deepcopy(ps_model)\n",
    "    # ps_model_copy.fit(candidate.iloc[:,:causal_param_first_index], candidate['T'])\n",
    "    t_cand_pred = ps_model.predict(candidate.iloc[:,:causal_param_first_index]) # predict on host!\n",
    "    mse_cand = abs(mean_squared_error(t_cand_pred, candidate['T']) - mse_host)\n",
    "    mse_diff_list.append(mse_cand)\n",
    "\n",
    "similarity_pscore_ranking = sorted(range(len(mse_diff_list)), key=lambda i: mse_diff_list[i], reverse=True) \n",
    "# the more diff in pscore the better so reverse=True\n",
    "\n",
    "\n",
    "print(random_ranking)\n",
    "print(sample_size_order)\n",
    "print(similarity_cov_distrib_ranking)\n",
    "print(similarity_pscore_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sample_size_order).index(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision_at_1': [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " 'precision_at_3': [0.3333333333333333,\n",
       "  0.3333333333333333,\n",
       "  0.3333333333333333,\n",
       "  0.6666666666666666,\n",
       "  0.3333333333333333,\n",
       "  0.3333333333333333],\n",
       " 'precision_at_5': [0.6, 0.6, 0.4, 0.6, 0.4, 0.6],\n",
       " 'tau': [0.06666666666666667,\n",
       "  0.3333333333333333,\n",
       "  -0.1111111111111111,\n",
       "  0.15555555555555553,\n",
       "  -0.022222222222222223,\n",
       "  0.28888888888888886],\n",
       " 'rho': [0.06666666666666665,\n",
       "  0.34545454545454546,\n",
       "  -0.12727272727272726,\n",
       "  0.1515151515151515,\n",
       "  -0.05454545454545454,\n",
       "  0.32121212121212117]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_to_ground_truth(correlation_with_true_rankings, true_cate_ranking, list(random_ranking),merged_mse=merged_mse, top_n = top_n, k = k)\n",
    "compare_to_ground_truth(correlation_with_true_rankings, true_cate_ranking, list(sample_size_order),merged_mse=merged_mse, top_n = top_n, k = k)\n",
    "compare_to_ground_truth(correlation_with_true_rankings, true_cate_ranking, list(similarity_cov_distrib_ranking),merged_mse=merged_mse, top_n = top_n, k = k)\n",
    "compare_to_ground_truth(correlation_with_true_rankings, true_cate_ranking, list(similarity_pscore_ranking),merged_mse=merged_mse, top_n = top_n, k = k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_at_1</th>\n",
       "      <th>precision_at_3</th>\n",
       "      <th>precision_at_5</th>\n",
       "      <th>tau</th>\n",
       "      <th>rho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>obs_closed_form</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caus_closed_form</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.345455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>-0.127273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample size</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.151515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similarity_cov_distrib_ranking</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.022222</td>\n",
       "      <td>-0.054545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similarity_pscore_ranking size</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.321212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                precision_at_1  precision_at_3  \\\n",
       "obs_closed_form                            0.0        0.333333   \n",
       "caus_closed_form                           0.0        0.333333   \n",
       "random                                     0.0        0.333333   \n",
       "sample size                                0.0        0.666667   \n",
       "similarity_cov_distrib_ranking             1.0        0.333333   \n",
       "similarity_pscore_ranking size             0.0        0.333333   \n",
       "\n",
       "                                precision_at_5       tau       rho  \n",
       "obs_closed_form                            0.6  0.066667  0.066667  \n",
       "caus_closed_form                           0.6  0.333333  0.345455  \n",
       "random                                     0.4 -0.111111 -0.127273  \n",
       "sample size                                0.6  0.155556  0.151515  \n",
       "similarity_cov_distrib_ranking             0.4 -0.022222 -0.054545  \n",
       "similarity_pscore_ranking size             0.6  0.288889  0.321212  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_with_true_rankings= pd.DataFrame.from_dict(correlation_with_true_rankings)\n",
    "correlation_with_true_rankings.index = ['obs_closed_form', 'caus_closed_form', 'random', 'sample size', 'similarity_cov_distrib_ranking', 'similarity_pscore_ranking size'] #, 'obs_from_samples', 'caus_from_samples']\n",
    "correlation_with_true_rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=-0.4222222222222222, pvalue=0.10831349206349207)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kendalltau(true_cate_ranking, merged_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bart stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_host, T_host, Y_host = host.drop(columns=['T','Y']).values, host['T'].values.astype(np.int32), host['Y'].values\n",
    "\n",
    "# prior_hyperparameters = {'sigma_0_sq':1, 'p_categorical_pr':0, 'p_categorical_trt':0 }\n",
    "# predictive_model_parameters={\"num_trees_pr\":200,\"num_trees_trt\":100}\n",
    "# conditional_model_param={\"num_trees_pr\":200}\n",
    "\n",
    "\n",
    "# for i, candidate in candidate_sites.items():\n",
    "\n",
    "#     print(\"from samples \"+str(i))\n",
    "#     X_cand, T_cand = candidate.drop(columns=['Y','T']).values, candidate['T'].values.astype(np.int32)\n",
    "\n",
    "#     bcf = BayesianCausalForest(\n",
    "#         prior_hyperparameters,\n",
    "#         predictive_model_parameters=predictive_model_parameters,\n",
    "#         conditional_model_param=conditional_model_param)\n",
    "#     bcf.store_train_data(X=X_host, T=T_host, Y=Y_host)\n",
    "    \n",
    "#     joint_eig = bcf.joint_EIG_calc(X_cand, T_cand, sampling_parameters)\n",
    "\n",
    "#     results[\"EIG_obs_bart\"].append(joint_eig[\"Obs EIG\"])\n",
    "#     results[\"EIG_caus_bart\"].append(joint_eig[\"Causal EIG\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pjake_kernel",
   "language": "python",
   "name": "pjake_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
